---
title: "Local Employment CART Analysis"
editor: visual
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
library(tidyverse)
library(sf)
library(ggrepel)
library(scales)
library(shiny)
library(shinycssloaders)
library(ggiraph)
library(kableExtra)
library(rmapshaper)
library(cowplot)
library(DT)
library(htmlwidgets)
library(RColorBrewer)
library(readxl)
library(janitor)
library(lubridate)
library(systemfonts)
reset_font_cache()
library(ggtext)
library(gmodels)
library(fastDummies)
library(car)
library(glmnet)
library(glmnetUtils)
library(pscl)
library(sjPlot)
library(rpart)
library(rpart.plot)
```

```{r themes and shapefiles, include=FALSE}
theme_bar <- theme_bw() +
  theme(panel.grid.major = element_line(color = "grey70", linewidth  = 0.1),
        panel.grid.minor = element_blank(),
        axis.ticks = element_blank(),
        axis.text = element_text(face = "bold"),
        panel.border = element_blank(),
        legend.background = element_rect(fill = "transparent", color = "transparent"),
        legend.key = element_rect(fill = "transparent"),
        legend.key.size = unit(1, "lines"),
        legend.margin = margin(0,0,0,0),
        legend.title = element_blank(),
        legend.text = element_text(margin = margin(l = 2)),
        text = element_text(family = "Arial") ,
        plot.title.position = "plot",
        plot.title = element_text(face = "bold"))

theme_line <- theme_bw() +
  theme(legend.background = element_rect(fill = "transparent", color = "transparent"),
        legend.key = element_rect(fill = "transparent"),
        legend.text = element_text(margin = margin(l = 2)),
        panel.grid.minor = element_blank(),
        panel.grid.major = element_line(color = "grey70", linewidth = 0.1),
        axis.ticks = element_blank(),
        axis.text = element_text(face = "bold"),
        panel.border = element_blank(),
        legend.margin = margin(0,0,0,0),
        legend.key.size = unit(1, "lines"),
        text = element_text(family = "Arial") ,
        plot.title.position = "plot",
        plot.title = element_text(face = "bold"))


theme_sf <- theme_bw() +
  theme(axis.text.x=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks=element_blank(),
        panel.background = element_blank(),
        panel.grid.major = element_line(color = "white"),
        panel.border = element_blank(),
        legend.title = element_blank(),
        legend.text = element_text(margin = margin(l = 2)),
        legend.margin = margin(0,0,0,0),
        legend.key.size = unit(1, "lines"),
        text = element_text(family = "Arial") ,
        plot.title.position = "plot",
        plot.title = element_text(face = "bold"))

regions <- read_csv("/Users/kellyasche/Library/CloudStorage/GoogleDrive-kasche@ruralmn.org/My Drive/Data Prep/R Projects/Join docs/county_regions.csv") %>%
    select(5,6) %>%
    unique() %>%
    mutate(edr = str_replace(edr, "  ", " "),
           planning.region = str_replace(planning.region, " Minnesota", ""),
           planning.region = fct_relevel(planning.region, "Northwest", "Northeast", "Central", "Seven County Mpls-St Paul", "Southwest", "Southeast"),
           edr = fct_relevel(edr, "EDR 1 - Northwest", "EDR 2 - Headwaters", "EDR 3 - Arrowhead", "EDR 4 - West Central", "EDR 5 - North Central", "EDR 6E- Southwest Central", "EDR 6W- Upper Minnesota Valley", "EDR 7E- East Central", "EDR 7W- Central", "EDR 8 - Southwest", "EDR 9 - South Central", "EDR 10 - Southeast", "EDR 11 - 7 County Twin Cities", "Minnesota"))

counties.regions <- read_csv("/Users/kellyasche/Library/CloudStorage/GoogleDrive-kasche@ruralmn.org/My Drive/Data Prep/R Projects/Join docs/county_regions.csv") %>%
  rename(mif = `MIF Region`) %>%
  mutate(countyfp = formatC(countyfp, width = 3, flag = "0"),
         Name = str_to_title(Name),
         Name = str_replace(Name, "Q", "q"),
         Name = str_replace(Name, "Of The", "of the"),
         Name = str_replace(Name, "Mcleod", "McLeod"),
         Dem_Desc = ifelse(Name == "Minnesota", "Minnesota", Dem_Desc) ,
         edr = str_replace(edr, "  ", " "),
         planning.region = str_replace(planning.region, " Minnesota", ""),
         planning.region = fct_relevel(planning.region, "Northwest", "Northeast", "Central", "Seven County Mpls-St Paul", "Southwest", "Southeast"),
         edr = fct_relevel(edr, "EDR 1 - Northwest", "EDR 2 - Headwaters", "EDR 3 - Arrowhead", "EDR 4 - West Central", "EDR 5 - North Central", "EDR 6E- Southwest Central", "EDR 6W- Upper Minnesota Valley", "EDR 7E- East Central", "EDR 7W- Central", "EDR 8 - Southwest", "EDR 9 - South Central", "EDR 10 - Southeast", "EDR 11 - 7 County Twin Cities", "Minnesota"),
         mif = ifelse(is.na(mif), "TC", mif),
         mif = as.factor(mif),
         mif = fct_relevel(mif, "NW", "NE", "WC", "EC", "SW", "SE", "TC"),
Dem_Desc = fct_relevel(Dem_Desc, "Entirely rural", "Town/rural mix", "Urban/town/rural mix", "Entirely urban"))


color.ruca <- c("Entirely rural" = "#009933", "Town/rural mix" = "#99CC33", "Urban/town/rural mix" = "#CC9966", "Entirely urban" = "#754C29", "Minnesota" = "black")

color.pr <- c("Northwest" = 	"#4575b4", "Northeast" = "grey", "Central" = "#fee090", "Seven County Mpls-St Paul" = "#d73027", "Southwest" = "#91bfdb", "Southeast" = "#fc8d59", "Minnesota" = "black")

color.edr <- c("EDR 1 - Northwest" = "#b3cde3", "EDR 2 - Headwaters" = "#8c96c6", "EDR 3 - Arrowhead" = "#fe9929", "EDR 4 - West Central" = "#8856a7", "EDR 5 - North Central" = "#810f7c", "EDR 6E- Southwest Central" = "#e5f5f9", "EDR 6W- Upper Minnesota Valley" = "#bdc9e1", "EDR 7E- East Central" = "#99d8c9", "EDR 7W- Central" = "#2ca25f", "EDR 8 - Southwest" = "#74a9cf", "EDR 9 - South Central" = "#0570b0", "EDR 10 - Southeast" = "#d7301f", "EDR 11 - 7 County Twin Cities" = "#d8b365", "Minnesota" = "black")

color.edr.simple <- c("EDR 1" = "#b3cde3", "EDR 2" = "#8c96c6", "EDR 3" = "#fe9929", "EDR 4" = "#8856a7", "EDR 5" = "#810f7c", "EDR 6E" = "#e5f5f9", "EDR 6W" = "#bdc9e1", "EDR 7E" = "#99d8c9", "EDR 7W" = "#2ca25f", "EDR 8" = "#74a9cf", "EDR 9" = "#0570b0", "EDR 10" = "#d7301f", "EDR 11" = "#d8b365", "Minnesota" = "black")

color.pr.edr <- c ("Northwest" = "#4575b4","Northeast" = "#e0f3f8", "Central" = "#fee090", "Seven County Mpls-St Paul" = "#d73027", "Southwest" = "#91bfdb", "Southeast" = "#fc8d59", "Minnesota" = "black", "EDR 1 - Northwest" = "#b3cde3", "EDR 2 - Headwaters" = "#8c96c6", "EDR 3 - Arrowhead" = "#fe9929", "EDR 4 - West Central" = "#8856a7", "EDR 5 - North Central" = "#810f7c", "EDR 6E- Southwest Central" = "#e5f5f9", "EDR 6W- Upper Minnesota Valley" = "#bdc9e1", "EDR 7E- East Central" = "#99d8c9", "EDR 7W- Central" = "#2ca25f", "EDR 8 - Southwest" = "#74a9cf", "EDR 9 - South Central" = "#0570b0", "EDR 10 - Southeast" = "#d7301f", "EDR 11 - 7 County Twin Cities" = "#d8b365")

mn_counties <- st_read("/Users/kellyasche/Library/CloudStorage/GoogleDrive-kasche@ruralmn.org/My Drive/Data Prep/R Projects/Shapefiles/County shapefiles/MNCounties_MNDOT.shp", quiet = TRUE) %>%
  ms_simplify(keep = .01, keep_shapes = TRUE) %>%
  rename(countyfp = FIPS_CODE)
```

```{r master dataset}

original <- read_csv("Data/SLEDS/Masters/After analysis/Master-after-ct.csv")

kable(head(original))

kable(names(original))
```

```{r joining masters}
master <- original %>%
  mutate_at(2:15, as.factor) %>%
  mutate_at(21:23, as.factor) %>%
  mutate(grad.year.1 = fct_relevel(grad.year.1, "Meaningful emp NE", "Meaningful emp MN", "Attending ps", "Not meaningful, not attending ps", "No MN emp record, not attending ps", "After 2023"),
         grad.year.5 = fct_relevel(grad.year.5, "Meaningful emp NE", "Meaningful emp MN", "Attending ps", "Not meaningful, not attending ps", "No MN emp record, not attending ps", "After 2023"),
         grad.year.10 = fct_relevel(grad.year.10, "Meaningful emp NE", "Meaningful emp MN", "Attending ps", "Not meaningful, not attending ps", "No MN emp record, not attending ps", "After 2023")) %>%
  droplevels()

```

<br>

We will use a tree-based method for classification - CART analysis. This type of analysis involves stratifying and/or segmenting the predictor space into a number of simple regions. Essentially, it's another way to see which independent variables play a role in if an individual has meaningful employment in the local region X. We will be using the independent variables that were identified as being important in the multiple correspondence analysis.

There are a number of states at which we categorize individuals in the dataset;

1.  Has meaningful employment in the Northeast region.
2.  Has meaningful employment in Minnesota, but not in Northeast Minnesota.
3.  Is attending post-secondary.
4.  Has a MN employment record but it's not meaningful, and not attending post-secondary.
5.  Does not have a MN employment record and is not attending post-secondary.

There are three "times" in which we checked to see if the individual had meaningful employment within these geographies;

1.  one year after graduating high school
2.  five years after graduation, and
3.  ten years after graduation.

Meaningful employment is determined by whether an individual worked 1,000 hours for an employer during time X. In addition, if the individual is working for an employer but not meaningful at time X but worked 1,000 hours for that employer during another year it's still considered "meaningful".

Due to time x potentially being passed the date of the latest data (2023) for some individuals, the analysis below will filter out all individuals where time x is after 2023.

The primary independent variables that the cross tables indicated as important are;

```{r list of ind var}
ind.var <- master %>%
  select(-PersonID, -grad.year.1, -grad.year.5, -grad.year.10)
  
ind.var.names <- ind.var %>%
  names()

ind.var %>%
  lapply(class)
```

<br>

# Methodology

We are going to use CART/Decision Trees to see which independent variables are important. One limitation of this method is that the dependent variable must be binary. So, how do we do this.

First, I would like to see what variables maybe playing a role in whether an individual has meaningful employment in the region at three times after graduating high school;

1.  one year after graduating high school
2.  five years after graduating high school
3.  ten years after graduating high school.

So the question is how to figure out the other side of the binary. If I throw the remaining categories into the other binary category, I may end up with a pretty muddy picture. For example, the variables that may play a role in whether someone has meaningful employment in MN vs. not having a MN employment record may be very different, yet they would be in the same group. This would make the decision tree hard to interpret.

To get around this, it might be best to analyze everything a few different ways;

-   Meaningful employment in the region vs.
    1.  meaningful employment in MN
    2.  not meaningful and not attending post-secondary
    3.  no MN employment record.
-   Meaningful employment in the region vs. all other categories aggregated

<br>

## Process

I'm using a three step process to try and figure out which variables are most important.

1.  Create a base model that let's the decision tree full grow.
2.  Create a pre-pruned model that will place parameters on it in order to get a simpler tree. The parameters will be the following;
    -   maxdepth: 3 to 6
    -   minsplit: 5% of n
    -   minbucket: round(minsplit / 3)
    -   If these parameters provide a tree with no splits, then I will use maxdepth = 6, eliminate the minbucket parameter, and reduce the minsplit until I get the highest accuracy possible.
3.  Create a post-pruned model, which will use cp in order to get a simpler decision tree. I use either of the following to identify the cp value;
    -   cp with the lowest xerror, if this has a lot of nsplits and creates an overly complicated tree, then I will use the cp with the next lowest xerror that is within the standard error the of cp with the lowest xerror.

<br>

## How to Interpret a Decision Tree

Each **node** and **branch** in a decision tree represents a **decision rule** based on the data. Here's how to read it from **top (root) to bottom (leaves)**:

### **1. Root Node (Top Node)**

This is where the first and most important split happens. The variable here has the **highest information gain** (i.e., it reduces uncertainty the most).

Example: `ps.grad.location = In region, Inside and outside region`

This is the first key factor that separates groups with different employment outcomes.

### **2. Branches (Edges)**

Represent decision outcomes (e.g., `Yes`, `No`, or thresholds like `ACTCompositeScore > 19.5`). They **funnel observations** down different paths based on their attribute values.

### **3. Internal Nodes**

Each of these applies a **new decision rule**, further narrowing the group. The tree uses variables in order of importance — high up = more impact.

### **4. Leaf Nodes (Terminal Nodes)**

Each leaf shows:

-   The **predicted class or outcome**
-   A **probability**: how certain the model is about that prediction
-   A **proportion** or count: how many cases fall into that node

Example:

-   Prediction: No meaningful emp NE
-   Probability: 0.84 (i.e., 84% chance)
-   Coverage: 77% of the population

### **Tips for Interpreting**

| Element                   | Interpretation                 |
|---------------------------|--------------------------------|
| **Top splits**            | Most important predictors      |
| **Deeper paths**          | More nuanced subgroups         |
| **High-probability leaf** | Strong prediction confidence   |
| **Wide node coverage**    | Large segment of data affected |

Putting It All Together

A path through the tree represents a **rule**:

*If* `ps.grad.location` = "In region" AND `MCA.M` \< 3 AND `cte.achievement` = "Concentrator"\

*Then* predict "No meaningful emp NE" with 84% certainty.

This is what makes decision trees interpretable: each path is a **clear if–then statement**.

<br>

# Meaningful emp in NE vs. meaningful emp in MN

This section will examine which variables seem to play a role in whether an individual has meaningful employment in the region, or in Minnesota.

<br>

## One year after graduation

It probably doesn't make sense to have a dataset with a bunch of post-secondary variables in it when exploring which variables make a difference in whether someone has meaningful workforce participation in the region one year after graduating high school. So I'm going to only include the variable ps.grad in the dataset.

```{r prep meaningful emp mn grad year 1}
meaningful.emp.mn.grad.year.1 <- master %>%
  filter(grad.year.1 %in% c("Meaningful emp NE", "Meaningful emp MN")) %>%
  select(-PersonID, -grad.year.5, -grad.year.10, -ps.grad.InstitutionSector, -ps.grad.location, -highest.cred.level) 

kable(names(meaningful.emp.mn.grad.year.1))
```

When filtering for individuals that had meaningful employment in NE vs MN one year after graduation we end up with `r comma(nrow(meaningful.emp.mn.grad.year.1))` individuals.The table below shows that a large majority of individuals have meaningful employment in the region - 79% compared to individuals with meaningful employment in MN, but not in the region.

<br>

```{r meaningful emp mn grad year 1 prop}
meaningful.emp.mn.grad.year.1.prop <- meaningful.emp.mn.grad.year.1 %>%
  group_by(grad.year.1) %>%
  summarize(n = n()) %>%
  ungroup() %>%
  mutate(pct = n / sum(n),
         pct = percent(pct, accuracy = .1)) %>%
  datatable(rownames = FALSE,
            options = list(columnDefs = list(list(className = "dt-center", targets = 1:2))))

```

<br>

### Base model

First we will split the data into two sets, Train and Test, in a 70:30 ratio. The Train set is used for training and creating the model. The Test set is considered to be a dummy production environment to test predictions and evaluate the accuracy of the model.

<br>

```{r split dataset into test and train meaningful emp MN grad year 1, echo=TRUE}
set.seed(1234)

sample_ind <- sample(nrow(meaningful.emp.mn.grad.year.1), nrow(meaningful.emp.mn.grad.year.1) *.7)

train <- meaningful.emp.mn.grad.year.1[sample_ind,]

test <- meaningful.emp.mn.grad.year.1[-sample_ind,]

```

<br>

Next, we create a decision tree model by calling the rpart function. Let's first create a base model with default parameters and value. The CP (complexity parameter) is used to control tree growth. If the cost of adding a variable is higher then the value of CP, then tree growth stops.

The summary shows that the lowest cross-validated error is 1.0410 and the nsplit is 2.

<br>

```{r create decision tree meaningful emp MN grad year 1, echo=TRUE, include = FALSE}
#Base model

meaningful.emp.mn.grad.year.1.model <- rpart(grad.year.1 ~ ., data = train, method = "class", control = rpart.control(cp = 0))

#Summary
summary(meaningful.emp.mn.grad.year.1.model)

```

```{r decision tree plot meaningful emp MN grad year 1}
#Plot tree
rpart.plot(meaningful.emp.mn.grad.year.1.model)

# Examine the complexity plot
printcp(meaningful.emp.mn.grad.year.1.model)

plotcp(meaningful.emp.mn.grad.year.1.model)

```

<br>

The resulting model produced a VERY complex tree with too many nodes that it isn't interpretable. However, examining the complexity parameters shows that I have an increasing cross-validated error which provides evidence of a decision tree with too much complexity.

<br>

```{r base model variable importance meaningful emp MN grad year 1, echo=TRUE}

meaningful.emp.mn.grad.year.1.model$variable.importance

importance <- meaningful.emp.mn.grad.year.1.model$variable.importance

importance <- sort(importance, decreasing = TRUE)

barplot(importance,
        main = "Variable Importance",
        xlab = "Variables",
        ylab = "Importance",
        col = "steelblue",
        las = 2,        # make axis labels vertical
        cex.names = 0.8 # smaller font if needed
)

```

Next, the accuracy of the model is computed and stored in a variable base_accuracy so we can compare it to our pruned trees later.

<br>

```{r model accuracy meaningful emp MN grad year 1, echo=TRUE}
test$pred <- predict(meaningful.emp.mn.grad.year.1.model, test, type = "class")

base_accuracy <- mean(test$pred == test$grad.year.1)

base_accuracy

```

<br>

### Pre-pruning

Next, we need to prune. We can either pre-prune or post-prune. We will start with pre-pruning and use each method - max depth, min depth, and min bucket. It's recommended that I start with the following parameters;

-   maxdepth: 3 to 6
-   minsplit: 5% of n which is 265
-   minbucket: round(minsplit / 3) which is 89

Unfortunately, these parameters produced a tree with zero splits. So the new parameters are the following;

-   maxdepth: 6
-   minsplit:
-   minbuck: eliminated

<br>

```{r pre pruning  meaningful emp MN grad year 1, echo=TRUE}
meaningful.emp.mn.grad.year.1.model.preprune <- rpart(grad.year.1 ~ ., data = train, method = "class", 
                   control = rpart.control(cp = 0, maxdepth = 6, minsplit = 50))

test$pred <- predict(meaningful.emp.mn.grad.year.1.model.preprune, test, type = "class")

accuracy_preprun <- mean(test$pred == test$grad.year.1)

accuracy_preprun
```

```{r pre pruning summary meaningful emp MN grad year 1, include=FALSE}

#Summary
summary(meaningful.emp.mn.grad.year.1.model.preprune)

```

The pre-pruning resulted in a significantly less complex tree with a .7878217 accuracy. Let's see what variables are important in this model.

```{r pre pruning plot meaningful emp MN grad year 1, echo=TRUE}
#Plot tree
rpart.plot(meaningful.emp.mn.grad.year.1.model.preprune)

# Examine the complexity plot
printcp(meaningful.emp.mn.grad.year.1.model.preprune)
```

The nodes show;

-   Dem_Desc
    -   Town/rural mix \| Urban/town/rural mix: 33% probability that they have meaningful employment in the region
        -   Meaningful emp in region: 30% probability if the have taken less than 9 total CTE courses
        -   Meaningful emp in MN: 59% probability if they have taken more than 9 total CTE courses
    -   Entirely rural
        -   Meaningful emp in region:
            -   lower ACTCompositeScore
            -   lower MCA.S score
            -   ps.grad - attending post-secondary \| never graduated from college

Overall, these are the most important themes;

-   Most important
    -   ACTCompositeScore
    -   Dem_Desc
    -   total.cte.courses.taken
    -   MCA.S
    -   ps.grad
-   Not as important
    -   RaceEthnicity
    -   MCA.M
    -   cte.achievement
    -   economic.status
    -   grad.year.covid
-   Missing
    -   range.school
    -   pseo.participant
    -   SpecialEdStatus
    -   took.ACT
    -   english.learner
    -   MCA.R

<br>

```{r pre pruning variable importance meaningful emp MN grad year 1, echo=TRUE}
meaningful.emp.mn.grad.year.1.model.preprune$variable.importance

importance <- meaningful.emp.mn.grad.year.1.model.preprune$variable.importance

importance <- sort(importance, decreasing = TRUE)

barplot(importance,
        main = "Variable Importance",
        xlab = "Variables",
        ylab = "Importance",
        col = "steelblue",
        las = 2,        # make axis labels vertical
        cex.names = 0.8 # smaller font if needed
)

```

<br>

### Post-pruning

Next, let's try postpruning. The idea here is to allow the decision tree to grow fully and observe the CP value. There are two methods for identifying the CP code;

1.  Use the cp value with the lowest xerror from the base model.
2.  Use the cp value with the next lowest xerror that is within the standard error.

<br>

```{r postpruning meaningful emp MN grad year 1, echo=TRUE}

cp_table <- meaningful.emp.mn.grad.year.1.model$cptable

min_xerror <- min(cp_table[, "xerror"])
min_xerror_se <- cp_table[which.min(cp_table[,"xerror"]), "xstd"]

threshold <- min_xerror + min_xerror_se

one_se_index <- which(cp_table[, "xerror"] <= threshold)[1] 

cp_1se <- cp_table[one_se_index, "CP"]

optimal_cp <- meaningful.emp.mn.grad.year.1.model$cptable[which.min(meaningful.emp.mn.grad.year.1.model$cptable[, "xerror"]), "CP"]


# Prune the hr_base_model based on the optimal cp value
meaningful.emp.mn.grad.year.1.model.postprune <- prune(meaningful.emp.mn.grad.year.1.model, cp = .00139752)

#Summary
summary(meaningful.emp.mn.grad.year.1.model.postprune)

#Plot tree
rpart.plot(meaningful.emp.mn.grad.year.1.model.postprune, nn = TRUE)

# Examine the complexity plot
printcp(meaningful.emp.mn.grad.year.1.model.postprune)
plotcp(meaningful.emp.mn.grad.year.1.model.postprune)


# Compute the accuracy of the pruned tree

test$pred <- predict(meaningful.emp.mn.grad.year.1.model.postprune, test, type = "class")

accuracy_postprun <- mean(test$pred == test$grad.year.1)

accuracy_postprun

```

<br>

We now have a very simple tree, that might be a little too simple.

The tree nodes provide the following;

-   Dem_Desc: Town/rural mix \| Urban/town/rural mix
    -   Yes: 22% probability that the individual will have meaningful employment in the region
    -   Entirely rural:
        -   Meaningful emp in region: Less than 9 CTE courses
        -   Meaningful emp in MN: More than 9 CTE courses

It tells me the following;

-   Most important
    -   Dem_Desc
    -   total.cte.coures.taken

<br>

```{r post pruning variable importance meaningful emp MN grad year 1, echo=TRUE}
meaningful.emp.mn.grad.year.1.model.postprune$variable.importance

importance <- meaningful.emp.mn.grad.year.1.model.postprune$variable.importance

importance <- sort(importance, decreasing = TRUE)

barplot(importance,
        main = "Variable Importance",
        xlab = "Variables",
        ylab = "Importance",
        col = "steelblue",
        las = 2,        # make axis labels vertical
        cex.names = 0.8 # smaller font if needed
)
```

<br>

Now let's compare the accuracy. The post-pruned tree does get a bit better accuracy.

```{r compare accuracy meaningful emp MN grad year 1, echo=TRUE}
data.frame(base_accuracy, accuracy_preprun, accuracy_postprun)

```

### Summary

The pre- and post-pruned trees provided better accuracy than the base model so let's use the most important variables from both.

-   Most important
    -   ACTCompositeScore
    -   Dem_Desc
    -   total.cte.courses.taken
    -   MCA.S
    -   ps.grad
-   Not as important
    -   RaceEthnicity
    -   MCA.M
    -   cte.achievement
    -   economic.status
    -   grad.year.covid
-   Missing
    -   range.school
    -   pseo.participant
    -   SpecialEdStatus
    -   took.ACT
    -   english.learner
    -   MCA.R

<br>

## Five years after graduation

We are now five years away from graduating high school, so including all of the post-secondary variables makes sense.

```{r prep meaningful emp mn grad year 5}
meaningful.emp.mn.grad.year.5 <- master %>%
  filter(grad.year.5 %in% c("Meaningful emp NE", "Meaningful emp MN")) %>%
  select(-PersonID, -grad.year.covid, -grad.year.1, -grad.year.10) 

kable(names(meaningful.emp.mn.grad.year.5))
```

When filtering for individuals that had meaningful employment in NE vs MN one year after graduation we end up with `r comma(nrow(meaningful.emp.mn.grad.year.5))` individuals.The table below shows that a large majority of individuals continue to have meaningful employment in the region - 64% compared to individuals with meaningful employment in MN, but not in the region.

<br>

```{r meaningful emp mn grad year 5 prop}
meaningful.emp.mn.grad.year.5.prop <- meaningful.emp.mn.grad.year.5 %>%
  group_by(grad.year.5) %>%
  summarize(n = n()) %>%
  ungroup() %>%
  mutate(pct = n / sum(n),
         pct = percent(pct, accuracy = .1)) %>%
  datatable(rownames = FALSE,
            options = list(columnDefs = list(list(className = "dt-center", targets = 1:2))))
```

<br>

### Base model

First we will split the data into two sets, Train and Test, in a 70:30 ratio. The Train set is used for training and creating the model. The Test set is considered to be a dummy production environment to test predictions and evaluate the accuracy of the model.

<br>

```{r split dataset into test and train meaningful emp MN grad year 5, echo=TRUE}
set.seed(1234)

sample_ind <- sample(nrow(meaningful.emp.mn.grad.year.5), nrow(meaningful.emp.mn.grad.year.5) *.7)

train <- meaningful.emp.mn.grad.year.5[sample_ind,]

test <- meaningful.emp.mn.grad.year.5[-sample_ind,]

```

<br>

Next, we create a decision tree model by calling the rpart function. Let's first create a base model with default parameters and value. The CP (complexity parameter) is used to control tree growth. If the cost of adding a variable is higher then the value of CP, then tree growth stops.

The summary shows that the lowest cross-validated error is .82700 and the nsplit is 10.

<br>

```{r create decision tree meaningful emp MN grad year 5, echo=TRUE, include = FALSE}
#Base model

meaningful.emp.mn.grad.year.5.model <- rpart(grad.year.5 ~ ., data = train, method = "class", control = rpart.control(cp = 0))

#Summary
summary(meaningful.emp.mn.grad.year.5.model)

```

```{r decision tree plot meaningful emp MN grad year 5}
#Plot tree
rpart.plot(meaningful.emp.mn.grad.year.5.model)

# Examine the complexity plot
printcp(meaningful.emp.mn.grad.year.5.model)

plotcp(meaningful.emp.mn.grad.year.5.model)

```

<br>

The resulting model produced a VERY complex tree with too many nodes that it isn't interpretable. However, examining the complexity parameters shows that I have an increasing cross-validated error which provides evidence of a decision tree with too much complexity.

<br>

```{r base model variable importance meaningful emp MN grad year 5, echo=TRUE}

meaningful.emp.mn.grad.year.5.model$variable.importance

importance <- meaningful.emp.mn.grad.year.5.model$variable.importance

importance <- sort(importance, decreasing = TRUE)

barplot(importance,
        main = "Variable Importance",
        xlab = "Variables",
        ylab = "Importance",
        col = "steelblue",
        las = 2,        # make axis labels vertical
        cex.names = 0.8 # smaller font if needed
)

```

Next, the accuracy of the model is computed and stored in a variable base_accuracy so we can compare it to our pruned trees later.

<br>

```{r model accuracy meaningful emp MN grad year 5, echo=TRUE}
test$pred <- predict(meaningful.emp.mn.grad.year.5.model, test, type = "class")

base_accuracy <- mean(test$pred == test$grad.year.5)

base_accuracy

```

<br>

### Pre-pruning

Next, we need to prune. We can either pre-prune or post-prune. We will start with pre-pruning and use each method - max depth, min depth, and min bucket. It's recommended that I start with the following parameters;

-   maxdepth: 3 to 6
-   minsplit: 5% of n which is 428
-   minbucket: round(minsplit / 3) which is 143

<br>

```{r pre pruning  meaningful emp MN grad year 5, echo=TRUE}
meaningful.emp.mn.grad.year.5.model.preprune <- rpart(grad.year.5 ~ ., data = train, method = "class", 
                   control = rpart.control(cp = 0, maxdepth = 6, minsplit = 428, minbucket = 143))

test$pred <- predict(meaningful.emp.mn.grad.year.5.model.preprune, test, type = "class")

accuracy_preprun <- mean(test$pred == test$grad.year.5)

accuracy_preprun
```

```{r pre pruning summary meaningful emp MN grad year 5, include=FALSE}

#Summary
summary(meaningful.emp.mn.grad.year.5.model.preprune)

```

The pre-pruning resulted in a significantly less complex tree with a .6801714 accuracy. Let's see what variables are important in this model.

```{r pre pruning plot meaningful emp MN grad year 5, echo=TRUE}
#Plot tree
rpart.plot(meaningful.emp.mn.grad.year.5.model.preprune)

# Examine the complexity plot
printcp(meaningful.emp.mn.grad.year.5.model.preprune)
```

The nodes show;

-   ps.grad.location: in region \| Inside and outside region \| Never attended ps \| Outside region
    -   In Minnesota: Meaningful emp in MN
    -   Yes
        -   Meaningful emp in region
            -   ps.grad.InstitutionSector = 4
            -   MCA.M \< 3
            -   Town/rural mix \| urban/town/rural mix

Overall, these are the most important themes;

-   Most important
    -   ps.grad.location
    -   ps.grad.InstitutionSector
    -   highest.cred.level
    -   MCA.M
    -   Dem_Desc
-   Not as important
    -   MCA.R
    -   SpecialEdStatus
    -   took.ACT
    -   english.learner
    -   MCA.S
    -   total.cte.courses.taken
-   Missing
    -   economic.status
    -   range.school
    -   pseo.participant
    -   RaceEthnicity
    -   cte.achievement
    -   ps.grad
    -   ACTCompositeScore

<br>

```{r pre pruning variable importance meaningful emp MN grad year 5, echo=TRUE}
meaningful.emp.mn.grad.year.5.model.preprune$variable.importance

importance <- meaningful.emp.mn.grad.year.5.model.preprune$variable.importance

importance <- sort(importance, decreasing = TRUE)

barplot(importance,
        main = "Variable Importance",
        xlab = "Variables",
        ylab = "Importance",
        col = "steelblue",
        las = 2,        # make axis labels vertical
        cex.names = 0.8 # smaller font if needed
)

```

<br>

### Post-pruning

Next, let's try postpruning. The idea here is to allow the decision tree to grow fully and observe the CP value. There are two methods for identifying the CP code;

1.  Use the cp value with the lowest xerror from the base model.
2.  Use the cp value with the next lowest xerror that is within the standard error.

<br>

```{r postpruning meaningful emp MN grad year 5, echo=TRUE}

cp_table <- meaningful.emp.mn.grad.year.5.model$cptable

min_xerror <- min(cp_table[, "xerror"])
min_xerror_se <- cp_table[which.min(cp_table[,"xerror"]), "xstd"]

threshold <- min_xerror + min_xerror_se

one_se_index <- which(cp_table[, "xerror"] <= threshold)[1] 

cp_1se <- cp_table[one_se_index, "CP"]

optimal_cp <- meaningful.emp.mn.grad.year.5.model$cptable[which.min(meaningful.emp.mn.grad.year.5.model$cptable[, "xerror"]), "CP"]


# Prune the hr_base_model based on the optimal cp value
meaningful.emp.mn.grad.year.5.model.postprune <- prune(meaningful.emp.mn.grad.year.5.model, cp = optimal_cp)

#Summary
summary(meaningful.emp.mn.grad.year.5.model.postprune)

#Plot tree
rpart.plot(meaningful.emp.mn.grad.year.5.model.postprune, nn = TRUE)

# Examine the complexity plot
printcp(meaningful.emp.mn.grad.year.5.model.postprune)
plotcp(meaningful.emp.mn.grad.year.5.model.postprune)


# Compute the accuracy of the pruned tree

test$pred <- predict(meaningful.emp.mn.grad.year.5.model.postprune, test, type = "class")

accuracy_postprun <- mean(test$pred == test$grad.year.5)

accuracy_postprun

```

<br>

The post-pruned tree has a bit more complexity and a bit higher accuracy.

The tree nodes provide the following;

-   ps.grad.location: in region \| Inside and outside region \| Never attended ps \| Outside region
    -   In Minnesota: Meaningful emp in MN
    -   Yes
        -   Meaningful emp in region
            -   ps.grad.InstitutionSector = 4
            -   MCA.M \< 3
            -   Town/rural mix \| urban/town/rural mix
            -   CTE Concentrator or Completor

The variables with most importance include;

-   Most important
    -   ps.grad.location
    -   ps.grad.InstitutionSector
    -   highest.cred.level
    -   MCA.M
    -   Dem_Desc
-   Less importance
    -   MCA.R
    -   ACTCompositeScore
    -   cte.achievement
    -   took.ACT
    -   total.cte.courses.taken
    -   SpecialEdStatus
    -   english.learner
    -   MCA.S
    -   RaceEthnicity
-   Missing
    -   range.school

<br>

```{r post pruning variable importance meaningful emp MN grad year 5, echo=TRUE}
meaningful.emp.mn.grad.year.5.model.postprune$variable.importance

importance <- meaningful.emp.mn.grad.year.5.model.postprune$variable.importance

importance <- sort(importance, decreasing = TRUE)

barplot(importance,
        main = "Variable Importance",
        xlab = "Variables",
        ylab = "Importance",
        col = "steelblue",
        las = 2,        # make axis labels vertical
        cex.names = 0.8 # smaller font if needed
)
```

<br>

Now let's compare the accuracy. The post-pruned tree does get a bit better accuracy.

```{r compare accuracy meaningful emp MN grad year 5, echo=TRUE}
data.frame(base_accuracy, accuracy_preprun, accuracy_postprun)

```

### Summary

The pre- and post-pruned trees provided better accuracy than the base model so let's use the most important variables from both.

-   Most important
    -   ps.grad.location
    -   ps.grad.InstitutionSector
    -   highest.cred.level
    -   MCA.M
    -   Dem_Desc
-   Less importance
    -   MCA.R
    -   ACTCompositeScore
    -   cte.achievement
    -   took.ACT
    -   total.cte.courses.taken
    -   SpecialEdStatus
    -   english.learner
    -   MCA.S
    -   RaceEthnicity
-   Missing
    -   range.school

<br>

## Ten years after graduation

We are now five years away from graduating high school, so including all of the post-secondary variables makes sense.

```{r prep meaningful emp mn grad year 10}
meaningful.emp.mn.grad.year.10 <- master %>%
  filter(grad.year.10 %in% c("Meaningful emp NE", "Meaningful emp MN")) %>%
  select(-PersonID, -grad.year.covid, -grad.year.1, -grad.year.5) 

kable(names(meaningful.emp.mn.grad.year.10))
```

When filtering for individuals that had meaningful employment in NE vs MN one year after graduation we end up with `r comma(nrow(meaningful.emp.mn.grad.year.10))` individuals.The table below shows that a large majority of individuals continue to have meaningful employment in the region - 61% compared to individuals with meaningful employment in MN, but not in the region.

<br>

```{r meaningful emp mn grad year 10 prop}
meaningful.emp.mn.grad.year.10.prop <- meaningful.emp.mn.grad.year.10 %>%
  group_by(grad.year.10) %>%
  summarize(n = n()) %>%
  ungroup() %>%
  mutate(pct = n / sum(n),
         pct = percent(pct, accuracy = .1)) %>%
  datatable(rownames = FALSE,
            options = list(columnDefs = list(list(className = "dt-center", targets = 1:2))))

meaningful.emp.mn.grad.year.10.prop
```

<br>

### Base model

First we will split the data into two sets, Train and Test, in a 70:30 ratio. The Train set is used for training and creating the model. The Test set is considered to be a dummy production environment to test predictions and evaluate the accuracy of the model.

<br>

```{r split dataset into test and train meaningful emp NE grad year 10, echo=TRUE}
set.seed(1234)

sample_ind <- sample(nrow(meaningful.emp.mn.grad.year.10), nrow(meaningful.emp.mn.grad.year.10) *.7)

train <- meaningful.emp.mn.grad.year.10[sample_ind,]

test <- meaningful.emp.mn.grad.year.10[-sample_ind,]

```

<br>

Next, we create a decision tree model by calling the rpart function. Let's first create a base model with default parameters and value. The CP (complexity parameter) is used to control tree growth. If the cost of adding a variable is higher then the value of CP, then tree growth stops.

The summary shows that the lowest cross-validated error is .87347 and the nsplit is 33.

<br>

```{r create decision tree meaningful emp MN grad year 10, echo=TRUE, include = FALSE}
#Base model

meaningful.emp.mn.grad.year.10.model <- rpart(grad.year.10 ~ ., data = train, method = "class", control = rpart.control(cp = 0))

#Summary
summary(meaningful.emp.mn.grad.year.10.model)

```

```{r decision tree plot meaningful emp MN grad year 10}
#Plot tree
rpart.plot(meaningful.emp.mn.grad.year.10.model)

# Examine the complexity plot
printcp(meaningful.emp.mn.grad.year.10.model)

plotcp(meaningful.emp.mn.grad.year.10.model)

```

<br>

The resulting model produced a VERY complex tree with too many nodes that it isn't interpretable. However, examining the complexity parameters shows that I have an increasing cross-validated error which provides evidence of a decision tree with too much complexity.

<br>

```{r base model variable importance meaningful emp MN grad year 10, echo=TRUE}

meaningful.emp.mn.grad.year.10.model$variable.importance

importance <- meaningful.emp.mn.grad.year.10.model$variable.importance

importance <- sort(importance, decreasing = TRUE)

barplot(importance,
        main = "Variable Importance",
        xlab = "Variables",
        ylab = "Importance",
        col = "steelblue",
        las = 2,        # make axis labels vertical
        cex.names = 0.8 # smaller font if needed
)

```

Next, the accuracy of the model is computed and stored in a variable base_accuracy so we can compare it to our pruned trees later.

<br>

```{r model accuracy meaningful emp MN grad year 10, echo=TRUE}
test$pred <- predict(meaningful.emp.mn.grad.year.10.model, test, type = "class")

base_accuracy <- mean(test$pred == test$grad.year.10)

base_accuracy

```

<br>

### Pre-pruning

Next, we need to prune. We can either pre-prune or post-prune. We will start with pre-pruning and use each method - max depth, min depth, and min bucket. It's recommended that I start with the following parameters;

-   maxdepth: 3 to 6
-   minsplit: 5% of n which is 280
-   minbucket: round(minsplit / 3) which is 93

<br>

```{r pre pruning  meaningful emp MN grad year 10, echo=TRUE}
meaningful.emp.mn.grad.year.10.model.preprune <- rpart(grad.year.10 ~ ., data = train, method = "class", 
                   control = rpart.control(cp = 0, maxdepth = 6, minsplit = 280, minbucket = 93))

test$pred <- predict(meaningful.emp.mn.grad.year.10.model.preprune, test, type = "class")

accuracy_preprun <- mean(test$pred == test$grad.year.10)

accuracy_preprun
```

```{r pre pruning summary meaningful emp MN grad year 10, include=FALSE}

#Summary
summary(meaningful.emp.mn.grad.year.10.model.preprune)

```

The pre-pruning resulted in a significantly less complex tree with a .6609161 accuracy. Let's see what variables are important in this model.

```{r pre pruning plot meaningful emp MN grad year 10, echo=TRUE}
#Plot tree
rpart.plot(meaningful.emp.mn.grad.year.10.model.preprune)

# Examine the complexity plot
printcp(meaningful.emp.mn.grad.year.10.model.preprune)
```

The nodes show;

-   ps.grad.location: in region \| Inside and outside region \| Never attended ps \| Outside region
    -   In Minnesota: Meaningful emp in MN
    -   Yes
        -   highest.cred.level: associate degree \| Less than Associate degree
        -   MCA.M \< 3
        -   ACTCompositeScore \< 29
        -   Dem_Desc = Urban/town/rural mix
        -   economic.status = 0

Overall, these are the most important themes;

-   Most important
    -   ps.grad.location
    -   ps.grad.InstitutionSector
    -   highest.cred.level
-   Not as importance
    -   MCA.M
    -   ACTCompositeScore
    -   MCA.R
    -   Dem_Desc
    -   economic.status
    -   took.ACT
    -   ps.grad
    -   SpecialEdStatus
    -   cte.achievement
    -   total.cte.courses.taken
    -   RaceEthnicity
-   Missing
    -   range.school
    -   pseo.participant
    -   english.learner
    -   MCA.S

<br>

```{r pre pruning variable importance meaningful emp MN grad year 10, echo=TRUE}
meaningful.emp.mn.grad.year.10.model.preprune$variable.importance

importance <- meaningful.emp.mn.grad.year.10.model.preprune$variable.importance

importance <- sort(importance, decreasing = TRUE)

barplot(importance,
        main = "Variable Importance",
        xlab = "Variables",
        ylab = "Importance",
        col = "steelblue",
        las = 2,        # make axis labels vertical
        cex.names = 0.8 # smaller font if needed
)

```

<br>

### Post-pruning

Next, let's try postpruning. The idea here is to allow the decision tree to grow fully and observe the CP value. There are two methods for identifying the CP code;

1.  Use the cp value with the lowest xerror from the base model.
2.  Use the cp value with the next lowest xerror that is within the standard error.

<br>

```{r postpruning meaningful emp MN grad year 10, echo=TRUE}

cp_table <- meaningful.emp.mn.grad.year.10.model$cptable

min_xerror <- min(cp_table[, "xerror"])
min_xerror_se <- cp_table[which.min(cp_table[,"xerror"]), "xstd"]

threshold <- min_xerror + min_xerror_se

one_se_index <- which(cp_table[, "xerror"] <= threshold)[1] 

cp_1se <- cp_table[one_se_index, "CP"]

optimal_cp <- meaningful.emp.mn.grad.year.10.model$cptable[which.min(meaningful.emp.mn.grad.year.10.model$cptable[, "xerror"]), "CP"]


# Prune the hr_base_model based on the optimal cp value
meaningful.emp.mn.grad.year.10.model.postprune <- prune(meaningful.emp.mn.grad.year.10.model, cp = optimal_cp)

#Summary
summary(meaningful.emp.mn.grad.year.10.model.postprune)

#Plot tree
rpart.plot(meaningful.emp.mn.grad.year.10.model.postprune, nn = TRUE)

# Examine the complexity plot
printcp(meaningful.emp.mn.grad.year.10.model.postprune)
plotcp(meaningful.emp.mn.grad.year.10.model.postprune)


# Compute the accuracy of the pruned tree

test$pred <- predict(meaningful.emp.mn.grad.year.10.model.postprune, test, type = "class")

accuracy_postprun <- mean(test$pred == test$grad.year.10)

accuracy_postprun

```

<br>

The post-pruned tree has a bit more complexity and a bit higher accuracy.

The nodes show;

-   ps.grad.location: in region \| Inside and outside region \| Never attended ps \| Outside region
    -   In Minnesota: Meaningful emp in MN
    -   Yes
        -   highest.cred.level: associate degree \| Less than Associate degree
        -   MCA.M \< 3
        -   ACTCompositeScore lower
        -   Dem_Desc = Urban/town/rural mix
        -   economic.status = 0
        -   cte engagement

Overall, these are the most important themes;

-   Most important
    -   ps.grad.location
    -   ps.grad.InstitutionSector
    -   highest.cred.level
    -   ACTCompositeScore
    -   Dem_Desc
    -   MCA.M
    -   total.cte.courses.taken
-   Not as importance
    -   took.ACT
    -   cte.achievement
    -   MCA.R
    -   ps.grad
    -   economic.status
    -   RaceEthnicity
    -   pseo.participant
    -   SpecialEdStatus
-   Missing
    -   range.school
    -   MCA.S

<br>

```{r post pruning variable importance meaningful emp NE grad year 10, echo=TRUE}
meaningful.emp.mn.grad.year.10.model.postprune$variable.importance

importance <- meaningful.emp.mn.grad.year.10.model.postprune$variable.importance

importance <- sort(importance, decreasing = TRUE)

barplot(importance,
        main = "Variable Importance",
        xlab = "Variables",
        ylab = "Importance",
        col = "steelblue",
        las = 2,        # make axis labels vertical
        cex.names = 0.8 # smaller font if needed
)
```

<br>

Now let's compare the accuracy. The post-pruned tree does get a bit better accuracy.

```{r compare accuracy meaningful emp NE grad year 10, echo=TRUE}
data.frame(base_accuracy, accuracy_preprun, accuracy_postprun)

```

### Summary

The pre- and post-pruned trees provided better accuracy than the base model so let's use the most important variables from both.

-   Most important
    -   ps.grad.location
    -   ps.grad.InstitutionSector
    -   highest.cred.level
-   Not as importance
    -   MCA.M
    -   ACTCompositeScore
    -   MCA.R
    -   Dem_Desc
    -   economic.status
    -   took.ACT
    -   ps.grad
    -   SpecialEdStatus
    -   cte.achievement
    -   total.cte.courses.taken
    -   RaceEthnicity
-   Missing
    -   range.school
    -   pseo.participant
    -   english.learner
    -   MCA.S

<br>

# Meaningful emp in NE

First, let's re-categorize the dependent variables so that they are binary.

<br>

```{r prep meaningful emp in ne, echo=TRUE}

meaningful.emp.ne <- master %>%
  mutate(grad.year.1 = ifelse(grad.year.1 %in% c("Meaningful emp NE"), "Meaningful emp NE", 
                              ifelse(grad.year.1 %in% c("Meaningful emp MN", "Not meaningful, not attending ps", "No MN emp record, not attending ps"), "No meaningful emp NE",
                                     ifelse(grad.year.1 == "After 2023", "After 2023",
                                            ifelse(grad.year.1 == "Attending ps", "Attending ps", as.character(grad.year.1))))),
         grad.year.1 = as.factor(grad.year.1),
         grad.year.5 = ifelse(grad.year.5 %in% c("Meaningful emp NE"), "Meaningful emp NE", 
                              ifelse(grad.year.5 %in% c("Meaningful emp MN", "Not meaningful, not attending ps", "No MN emp record, not attending ps"), "No meaningful emp NE",
                                     ifelse(grad.year.5 == "After 2023", "After 2023",
                                            ifelse(grad.year.5 == "Attending ps", "Attending ps", as.character(grad.year.5))))),
         grad.year.5 = as.factor(grad.year.5),
         grad.year.10 = ifelse(grad.year.10 %in% c("Meaningful emp NE"), "Meaningful emp NE", 
                              ifelse(grad.year.10 %in% c("Meaningful emp MN", "Not meaningful, not attending ps", "No MN emp record, not attending ps"), "No meaningful emp NE",
                                     ifelse(grad.year.10 == "After 2023", "After 2023",
                                            ifelse(grad.year.10 == "Attending ps", "Attending ps", as.character(grad.year.10))))),
         grad.year.10 = as.factor(grad.year.10),
         grad.year.1 = fct_relevel(grad.year.1, "Meaningful emp NE", "No meaningful emp NE", "Attending ps", "After 2023"),
         grad.year.5 = fct_relevel(grad.year.5, "Meaningful emp NE", "No meaningful emp NE", "Attending ps", "After 2023"),
         grad.year.10 = fct_relevel(grad.year.10, "Meaningful emp NE", "No meaningful emp NE", "Attending ps", "After 2023"))

```

<br>

## One year after graduation

Since our dependent variable includes a state in which someone is attending post-secondary and the post-secondary variables are related to an individual finishing post-secondary, we will remove "ps.grad.InstitutionSector" and the "highest.cred.level" variable from the analysis.

```{r prep meaningful emp SW grad year 1}
meaningful.emp.ne.grad.year.1 <- meaningful.emp.ne %>%
  filter(grad.year.1 != "After 2023") %>%
  filter(grad.year.1 != "Attending ps") %>%
  select(-PersonID, -grad.year.5, -grad.year.10) 

kable(names(meaningful.emp.ne.grad.year.1))
```

### Base model

First we will split the data into two sets, Train and Test, in a 70:30 ratio. The Train set is used for training and creating the model. The Test set is considered to be a dummy production environment to test predictions and evaluate the accuracy of the model.

<br>

```{r split dataset into test and train meaningful emp NE grad year 1, echo=TRUE}
set.seed(1234)

sample_ind <- sample(nrow(meaningful.emp.ne.grad.year.1), nrow(meaningful.emp.ne.grad.year.1) *.7)

train <- meaningful.emp.ne.grad.year.1[sample_ind,]

test <- meaningful.emp.ne.grad.year.1[-sample_ind,]

```

<br>

Next, we create a decision tree model by calling the rpart function. Let's first create a base model with default parameters and value. The CP (complexity parameter) is used to control tree growth. If the cost of adding a variable is higher then the value of CP, then tree growth stops.

The summary shows that the lowest cross-validated error is .95105 and the nsplit is 2.

<br>

```{r create decision tree meaningful emp NE grad year 1, echo=TRUE, include = FALSE}
#Base model

meaningful.emp.ne.grad.year.1.model <- rpart(grad.year.1 ~ ., data = train, method = "class", control = rpart.control(cp = 0))

#Summary
summary(meaningful.emp.ne.grad.year.1.model)

```

```{r decision tree plot meaningful emp NE grad year 1}
#Plot tree
rpart.plot(meaningful.emp.ne.grad.year.1.model)

# Examine the complexity plot
printcp(meaningful.emp.ne.grad.year.1.model)

plotcp(meaningful.emp.ne.grad.year.1.model)

```

<br>

The resulting model produced a VERY complex tree with too many nodes that it isn't interpretable. However, examining the complexity parameters shows that I have an increasing cross-validated error which provides evidence of a decision tree with too much complexity.

Below are the values in variable importance and there are a couple of themes of importance;

1.  post-secondary pathway
2.  cte involvement
3.  Prep for post-secondary
4.  demographics, range school,

<br>

```{r base model variable importance meaningful emp NE grad year 1, echo=TRUE}

meaningful.emp.ne.grad.year.1.model$variable.importance

importance <- meaningful.emp.ne.grad.year.1.model$variable.importance

importance <- sort(importance, decreasing = TRUE)

barplot(importance,
        main = "Variable Importance",
        xlab = "Variables",
        ylab = "Importance",
        col = "steelblue",
        las = 2,        # make axis labels vertical
        cex.names = 0.8 # smaller font if needed
)

```

Next, the accuracy of the model is computed and stored in a variable base_accuracy so we can compare it to our pruned trees later.

<br>

```{r model accuracy meaningful emp NE grad year 1, echo=TRUE}
test$pred <- predict(meaningful.emp.ne.grad.year.1.model, test, type = "class")

base_accuracy <- mean(test$pred == test$grad.year.1)

base_accuracy

```

<br>

### Pre-pruning

Next, we need to prune. We can either pre-prune or post-prune. We will start with pre-pruning and use each method - max depth, min depth, and min bucket. It's recommended that I start with the following parameters;

-   maxdepth: 3 to 6
-   minsplit: 5% of n which is 1,138
-   minbucket: round(minsplit / 3) - 379

<br>

```{r pre pruning  meaningful emp NE grad year 1, echo=TRUE}
# Grow a tree with minsplit of 40 and max depth of 10
meaningful.emp.ne.grad.year.1.model.preprune <- rpart(grad.year.1 ~ ., data = train, method = "class", 
                   control = rpart.control(cp = 0, maxdepth = 3, minsplit = 1138, minbucket = 379))

```

```{r pre pruning summary meaningful emp NE grad year 1, include=FALSE}

#Summary
summary(meaningful.emp.ne.grad.year.1.model.preprune)
```

```{r pre pruning plot meaningful emp NE grad year 1, echo=TRUE}
#Plot tree
rpart.plot(meaningful.emp.ne.grad.year.1.model.preprune)

# Examine the complexity plot
printcp(meaningful.emp.ne.grad.year.1.model.preprune)
plotcp(meaningful.emp.ne.grad.year.1.model.preprune)


# Compute the accuracy of the pruned tree

test$pred <- predict(meaningful.emp.ne.grad.year.1.model.preprune, test, type = "class")

accuracy_preprun <- mean(test$pred == test$grad.year.1)

accuracy_preprun
```

The pre-pruning resulted in a significantly less complex tree with a .827 accuracy. Let's see what variables are important in this model.

Overall, these are the most important themes;

-   Most important - post-secondary pathways
    -   ps.grad.location
    -   ps.grad.InstitutionSector
    -   highest.cred.level
    -   ps.grad
-   Less important
    -   SpecialEdStatus
    -   Prep for post-secondary
        -   took.ACT
        -   MCA.R
    -   english.learner
    -   grad.year.covid
-   Missing:
    -   economic.status
    -   range.school
    -   pseo.participant
    -   RaceEthnicity
    -   Dem_Desc
    -   CTE engagement
    -   ACTCompositeScore
    -   MCA.S
    -   MCA.M

<br>

```{r pre pruning variable importance meaningful emp SW grad year 1, echo=TRUE}
meaningful.emp.ne.grad.year.1.model.preprune$variable.importance

importance <- meaningful.emp.ne.grad.year.1.model.preprune$variable.importance

importance <- sort(importance, decreasing = TRUE)

barplot(importance,
        main = "Variable Importance",
        xlab = "Variables",
        ylab = "Importance",
        col = "steelblue",
        las = 2,        # make axis labels vertical
        cex.names = 0.8 # smaller font if needed
)
```

<br>

### Post-pruning

Next, let's try postpruning. The idea here is to allow the decision tree to grow fully and observe the CP value. There are two methods for identifying the CP code;

1.  Use the cp value with the lowest xerror from the base model.
2.  Use the cp value with the next lowest xerror that is within the standard error.

In this case, the lowest cp has only a couple of nsplits, so we will use that value.

<br>

```{r postpruning meaningful emp NE grad year 1, echo=TRUE}

cp_table <- meaningful.emp.ne.grad.year.1.model$cptable

min_xerror <- min(cp_table[, "xerror"])
min_xerror_se <- cp_table[which.min(cp_table[,"xerror"]), "xstd"]

threshold <- min_xerror + min_xerror_se

one_se_index <- which(cp_table[, "xerror"] <= threshold)[1] 

cp_1se <- cp_table[one_se_index, "CP"]

optimal_cp <- meaningful.emp.ne.grad.year.1.model$cptable[which.min(meaningful.emp.ne.grad.year.1.model$cptable[, "xerror"]), "CP"]


# Prune the hr_base_model based on the optimal cp value
meaningful.emp.ne.grad.year.1.model.postprune <- prune(meaningful.emp.ne.grad.year.1.model, cp = .0031024)

#Summary
summary(meaningful.emp.ne.grad.year.1.model.postprune)

#Plot tree
rpart.plot(meaningful.emp.ne.grad.year.1.model.postprune, nn = TRUE)

# Examine the complexity plot
printcp(meaningful.emp.ne.grad.year.1.model.postprune)
plotcp(meaningful.emp.ne.grad.year.1.model.postprune)


# Compute the accuracy of the pruned tree

test$pred <- predict(meaningful.emp.ne.grad.year.1.model.postprune, test, type = "class")

accuracy_postprun <- mean(test$pred == test$grad.year.1)

accuracy_postprun

```

<br>

We now have a very simple tree, that might be a little too simple. Big piece, though, is that 91% of the individuals that did not graduate from college in the region did not have meaningful employment in Northeast.

1.  ps.grad.location: in region \| inside and outside region
    -   No - 91% don't have meaningful employment in region
    -   Yes
        -   highest.cred.level: Associate degree \| Bachelor degree
            -   Yes- more likely to have meaningful employment in region
            -   No - less likely to have meaningful employment in region

It tells me the following;

-   Most important
    -   post-secondary pathways
        -   ps.grad.location
        -   ps.grad.InstitutionSector
        -   highest.cred.level
        -   ps.grad
-   Barely important
    -   Demographics
        -   RaceEthnicity
        -   SpecialEdStatus
        -   english.learner
        -   grad.year.covid
    -   A couple of post-secondary prep
        -   took.ACT
        -   MCA.R
-   Missing from base run
    -   Demographics
        -   economic.status
    -   Location of high school - ALL
        -   range.school
        -   Dem_Desc
    -   Nearly all of the Prep for post-secondary
        -   pseo.participant
        -   ACTCompositeScore
        -   MCA.M
        -   MCA.S
    -   CTE engagement - all
        -   cte.achievement
        -   total.cte.courses.taken

<br>

```{r post pruning variable importance meaningful emp NE grad year 1, echo=TRUE}
meaningful.emp.ne.grad.year.1.model.postprune$variable.importance

importance <- meaningful.emp.ne.grad.year.1.model.postprune$variable.importance

importance <- sort(importance, decreasing = TRUE)

barplot(importance,
        main = "Variable Importance",
        xlab = "Variables",
        ylab = "Importance",
        col = "steelblue",
        las = 2,        # make axis labels vertical
        cex.names = 0.8 # smaller font if needed
)
```

<br>

Now let's compare the accuracy. The post-pruned tree does get a bit better accuracy.

```{r compare accuracy meaningful emp NE grad year 1, echo=TRUE}
data.frame(base_accuracy, accuracy_preprun, accuracy_postprun)

```

### Summary

The variable importance across the models do not vary much. The most consistent variables that were high in the importance values were;

-   All of the post-secondary pathways
    -   ps.grad.location
    -   ps.grad.InstitutionSector
    -   highest.cred.level
    -   ps.grad
-   Demographics
    -   SpecialEdStatus
    -   english.learner
    -   grad.year.covid
-   post-secondary prep
-   Missing from base run
    -   CTE stuff
    -   Gender
    -   RaceEthnicity

<br>

## Five years after graduation

Next we will look at the variables importance at five years after graduation. At this point we will bring back the post-secondary variables.

```{r prep meaningful emp NE grad year 5}
meaningful.emp.ne.grad.year.5 <- meaningful.emp.ne %>%
  filter(grad.year.5 != "After 2023") %>%
  filter(grad.year.5 != "Attending ps") %>%
  droplevels() %>%
  select(-PersonID, -grad.year.1, -grad.year.10)

kable(names(meaningful.emp.ne.grad.year.5))
```

### Base model

First we will split the data into two sets, Train and Test, in a 70:30 ratio. The Train set is used for training and creating the model. The Test set is considered to be a dummy production environment to test predictions and evaluate the accuracy of the model.

<br>

```{r split dataset into test and train meaningful emp NE grad year 5, echo=TRUE}
set.seed(1234)

sample_ind <- sample(nrow(meaningful.emp.ne.grad.year.5), nrow(meaningful.emp.ne.grad.year.5) *.7)

train <- meaningful.emp.ne.grad.year.5[sample_ind,]

test <- meaningful.emp.ne.grad.year.5[-sample_ind,]
```

Next, we create a decision tree model by calling the rpart function. Let's first create a base model with default parameters and value. The CP (complexity parameter) is used to control tree growth. If the cost of adding a variable is higher then the value of CP, then tree growth stops.

The summary shows that the lowest cross-validated error is .99974 and the nsplit is 17.

<br>

```{r create decision tree meaningful emp NE grad year 5, echo=TRUE, include = FALSE}
#Base model

meaningful.emp.ne.grad.year.5.model <- rpart(grad.year.5 ~ ., data = train, method = "class", cp = 0)

#Summary
summary(meaningful.emp.ne.grad.year.5.model)

```

```{r decision tree plot meaningful emp ne grad year 5}
#Plot tree
rpart.plot(meaningful.emp.ne.grad.year.5.model)

# Examine the complexity plot
printcp(meaningful.emp.ne.grad.year.5.model)

plotcp(meaningful.emp.ne.grad.year.5.model)

```

<br>

The resulting model produced a VERY complex tree with too many nodes that it isn't interpretable. However, examining the complexity parameters shows that I have an increasing cross-validated error which provides evidence of a decision tree with too much complexity.

Below are the values in variable important and there are a couple of themes;

1.  Post-secondary pathway are significant
2.  CTE engagement is significant
3.  Post-secondary prep work is significant
4.  School rurality and whether it's on the range is important
5.  Demographics are a bit lower

<br>

```{r base model variable importance meaningful emp ne grad year 5, echo=TRUE}

meaningful.emp.ne.grad.year.5.model$variable.importance

importance <- meaningful.emp.ne.grad.year.5.model$variable.importance

importance <- sort(importance, decreasing = TRUE)

barplot(importance,
        main = "Variable Importance",
        xlab = "Variables",
        ylab = "Importance",
        col = "steelblue",
        las = 2,        # make axis labels vertical
        cex.names = 0.8 # smaller font if needed
)

```

Next, the accuracy of the model is computed and stored in a variable base_accuracy so we can compare it to our pruned trees later.

<br>

```{r model accuracy meaningful emp ne grad year 5, echo=TRUE}
test$pred <- predict(meaningful.emp.ne.grad.year.5.model, test, type = "class")

base_accuracy <- mean(test$pred == test$grad.year.5)

base_accuracy
```

### Pre-pruning

Next, we need to prune. We can either pre-prune or post-prune. We will start with pre-pruning and use each method - max depth, min depth, and min bucket. It's recommended that I start with the following parameters;

-   maxdepth: 3 to 6
-   minsplit: 5% of n which is 1,406
-   minbucket: round(minsplit / 3) - 469

Using these parameters provided a tree with no decision splits. So, I made adjustments to get to the best accuracy I could find and ended up with the following;

-   cp = 0
-   maxdepth = 6
-   minsplit = 150

<br>

```{r pre pruning  meaningful emp ne grad year 5, echo=TRUE}
# Grow a tree with minsplit of 40 and max depth of 10
meaningful.emp.ne.grad.year.5.model.preprune <- rpart(grad.year.5 ~ ., data = train, method = "class", 
                   control = rpart.control(cp = 0, maxdepth = 6, minsplit = 150))

```

```{r pre pruning summary meaningful emp ne grad year 5, include=FALSE}

#Summary
summary(meaningful.emp.ne.grad.year.5.model.preprune)
```

```{r pre pruning plot meaningful emp ne grad year 5, echo=TRUE}
#Plot tree
rpart.plot(meaningful.emp.ne.grad.year.5.model.preprune)

# Examine the complexity plot
printcp(meaningful.emp.ne.grad.year.5.model.preprune)
plotcp(meaningful.emp.ne.grad.year.5.model.preprune)


# Compute the accuracy of the pruned tree

test$pred <- predict(meaningful.emp.ne.grad.year.5.model.preprune, test, type = "class")

accuracy_preprun <- mean(test$pred == test$grad.year.5)

accuracy_preprun
```

The pre-pruning resulted in a significantly less complex tree with a .8079659 accuracy. Let's see what variables are important in this model.

The primary nodes are;

1.  ps.grad.location: in region \| Inside and outside region
    -   No: 84% chance with no meaningful employment in NE
    -   Yes:
        -   Non-range school
        -   Dem_Desc
        -   cte.achievement
        -   MCA.R
        -   MCA.M

One interesting node is that ther was a 50% probability that an individual would have meaningful employment in the region if their MCA - Math score was greater than 3. But that only covered 2% of population.

Primary variable themes are;

-   Most important:
    -   Post-secondary pathway
        -   ps.grad.location
        -   ps.grad.InstitutionSector
        -   highest.cred.level
        -   ps.grad
    -   range.school & Dem_Desc
    -   CTE engagement
-   Less important
    -   Prep for post-secondary
        -   MCA.M
        -   MCA.R
        -   took.ACT
-   Very low
    -   SpecialEdStatus
    -   EnglishLearner
    -   RaceEthnicity
-   Missing from previous
    -   grad.year.covid
    -   economic.status
    -   pseo.participant
    -   ACTCompositeScore

<br>

```{r pre pruning variable importance meaningful emp ne grad year 5, echo=TRUE}
meaningful.emp.ne.grad.year.5.model.preprune$variable.importance

importance <- meaningful.emp.ne.grad.year.5.model.preprune$variable.importance

importance <- sort(importance, decreasing = TRUE)

barplot(importance,
        main = "Variable Importance",
        xlab = "Variables",
        ylab = "Importance",
        col = "steelblue",
        las = 2,        # make axis labels vertical
        cex.names = 0.8 # smaller font if needed
)

```

### Post-pruning

Next, let's try postpruning. The idea here is to allow the decision tree to grow fully and observe the CP value. Next, we prune/cut the tree with the optimal CP value as the parameter as shown in below code.

We will start out by using the optimal method which is just choosing the cp value with the lowest xerror from the base model.

<br>

```{r postpruning meaningful emp ne grad year 5, echo=TRUE}
cp_table <- meaningful.emp.ne.grad.year.5.model$cptable

min_xerror <- min(cp_table[, "xerror"])
min_xerror_se <- cp_table[which.min(cp_table[,"xerror"]), "xstd"]

threshold <- min_xerror + min_xerror_se

one_se_index <- which(cp_table[, "xerror"] <= threshold)[1] 

cp_1se <- cp_table[one_se_index, "CP"]

optimal_cp <- meaningful.emp.ne.grad.year.5.model$cptable[which.min(meaningful.emp.ne.grad.year.5.model$cptable[, "xerror"]), "CP"]

# Prune the hr_base_model based on the optimal cp value
meaningful.emp.ne.grad.year.5.model.postprune <- prune(meaningful.emp.ne.grad.year.5.model, cp = optimal_cp)

#Summary
summary(meaningful.emp.ne.grad.year.5.model.postprune)

#Plot tree
rpart.plot(meaningful.emp.ne.grad.year.5.model.postprune)

# Examine the complexity plot
printcp(meaningful.emp.ne.grad.year.5.model.postprune)
plotcp(meaningful.emp.ne.grad.year.5.model.postprune)


# Compute the accuracy of the pruned tree

test$pred <- predict(meaningful.emp.ne.grad.year.5.model.postprune, test, type = "class")

accuracy_postprun <- mean(test$pred == test$grad.year.5)

accuracy_postprun

```

<br>

When using the cp value with the lowest xerror, we end up with a slightly complex tree, but it's the best we can get. The tree nodes provide the following

-   ps.grad.location: In region \| inside and outside region
    -   No: 80% probability for no meaningful employment in region
    -   Yes
        -   Range school
        -   Dem_Desc
        -   cte.achievement
        -   cte.courses.taken
        -   SpecialEdStatus
        -   pseo.participant
        -   MCA.M
        -   MCA.S
        -   ACTCompositeScore
        -   highest.cred.level
        -   ps.grad.institution.sector

A few that indicate higher probability of having meaningful employment in the region;

-   total.cte.courses.taken \>= 3
-   MCA.S \>= 3
-   MCA.M \< 3

Here is the variabilities by importance

-   Most important
    -   post-secondary pathway
        -   ps.grad.location
        -   ps.grad.InstitutionSector
        -   highest.cred.level
        -   ps.grad
    -   Dem_Desc
    -   cte.achievement
    -   range.school
-   Less important
    -   SpecialEdStatus
    -   pseo.participant
    -   MCA.S
    -   MCA.M
    -   MCA.R
    -   demographics and prep for post-secondary

Missing variables

-   grad.year.covid

<br>

```{r post pruning variable importance grad year +5 county, echo=TRUE}
meaningful.emp.ne.grad.year.5.model.postprune$variable.importance

importance <- meaningful.emp.ne.grad.year.5.model.postprune$variable.importance

importance <- sort(importance, decreasing = TRUE)

barplot(importance,
        main = "Variable Importance",
        xlab = "Variables",
        ylab = "Importance",
        col = "steelblue",
        las = 2,        # make axis labels vertical
        cex.names = 0.8) # smaller font if needed

```

<br>

Now let's compare the accuracy. The pre-pruned tree is the most accurate.

```{r compare accuracy grad year +0 county, echo=TRUE}
data.frame(base_accuracy, accuracy_preprun, accuracy_postprun)

```

<br>

### Summary

The pre-pruned tree ended up being the most accurate.

-   Most important:
    -   Post-secondary pathway
        -   ps.grad.location
        -   ps.grad.InstitutionSector
        -   highest.cred.level
        -   ps.grad
    -   range.school & Dem_Desc
    -   CTE engagement
-   Less important
    -   Prep for post-secondary
        -   MCA.M
        -   MCA.R
        -   took.ACT
-   Very low
    -   SpecialEdStatus
    -   EnglishLearner
    -   RaceEthnicity
-   Missing from previous
    -   grad.year.covid
    -   economic.status
    -   pseo.participant
    -   ACTCompositeScore

<br>

## Ten years after graduation

Next we will look at the variables importance at five years after graduation. At this point we will bring back the post-secondary variables.

```{r prep meaningful emp ne grad year 10}
meaningful.emp.ne.grad.year.10 <- meaningful.emp.ne %>%
  filter(grad.year.10 != "After 2023") %>%
  filter(grad.year.10 != "Attending ps") %>%
  select(-PersonID, -grad.year.1, -grad.year.5)

kable(names(meaningful.emp.ne.grad.year.10))

```

<br>

### Base model

First we will split the data into two sets, Train and Test, in a 70:30 ratio. The Train set is used for training and creating the model. The Test set is considered to be a dummy production environment to test predictions and evaluate the accuracy of the model.

<br>

```{r split dataset into test and train meaningful emp ne grad year 10, echo=TRUE}
set.seed(1234)

sample_ind <- sample(nrow(meaningful.emp.ne.grad.year.10), nrow(meaningful.emp.ne.grad.year.10) *.7)

train <- meaningful.emp.ne.grad.year.10[sample_ind,]

test <- meaningful.emp.ne.grad.year.10[-sample_ind,]
```

Next, we create a decision tree model by calling the rpart function. Let's first create a base model with default parameters and value. The CP (complexity parameter) is used to control tree growth. If the cost of adding a variable is higher then the value of CP, then tree growth stops.

The base model shows that the cp value with the lowest xerror is 1.0157 and has 3 nsplits.

<br>

```{r create decision tree meaningful emp ne grad year 10, echo=TRUE, include = FALSE}
#Base model

meaningful.emp.ne.grad.year.10.model <- rpart(grad.year.10 ~ ., data = train, method = "class", cp = 0)

#Summary
summary(meaningful.emp.ne.grad.year.10.model)

```

```{r decision tree plot meaningful emp ne grad year 10}
#Plot tree
rpart.plot(meaningful.emp.ne.grad.year.10.model)

# Examine the complexity plot
printcp(meaningful.emp.ne.grad.year.10.model)

plotcp(meaningful.emp.ne.grad.year.10.model)

```

<br>

The resulting model produced a VERY complex tree with too many nodes that it isn't interpretable. However, examining the complexity parameters shows that I have an increasing cross-validated error which provides evidence of a decision tree with too much complexity.

Below are the values in variable important and it shows the following themes are important;

-   Most important
    -   Post-secondary pathway
        -   ps.grad.location
        -   ps.grad.InstitutionSector
        -   highest.cred.level
        -   ps.grad
    -   CTE engagement
        -   cte.courses.taken
        -   cte.achievement
    -   Prep for post-secondary
        -   ACTCompositeScore
        -   MCA.M
        -   MCA.R
        -   MCA.S
        -   took.ACT
        -   pseo.participant
    -   High school location
        -   Dem_Desc
        -   range.school
-   Less important
    -   Demographics
        -   SpecialEdStatus
        -   RaceEthnicity
        -   economic.status
        -   english.learner
-   Missing
    -   grad.year.covid

<br>

```{r base model variable importance meaningful emp ne grad year 10, echo=TRUE}

meaningful.emp.ne.grad.year.10.model$variable.importance

importance <- meaningful.emp.ne.grad.year.10.model$variable.importance

importance <- sort(importance, decreasing = TRUE)

barplot(importance,
        main = "Variable Importance",
        xlab = "Variables",
        ylab = "Importance",
        col = "steelblue",
        las = 2,        # make axis labels vertical
        cex.names = 0.8) # smaller font if needed
```

Next, the accuracy of the model is computed and stored in a variable base_accuracy so we can compare it to our pruned trees later.

<br>

```{r model accuracy meaningful emp ne grad year 10, echo=TRUE}
test$pred <- predict(meaningful.emp.ne.grad.year.10.model, test, type = "class")

base_accuracy <- mean(test$pred == test$grad.year.10)

base_accuracy
```

### Pre-pruning

Next, we need to prune. We can either pre-prune or post-prune. We will start with pre-pruning and use each method - max depth, min depth, and min bucket. It's recommended that I start with the following parameters;

-   maxdepth: 3 to 6
-   minsplit: 5% of n which is 987
-   minbucket: round(minsplit / 3) - 329

That provided a tree with zero splits. So the following parameters were used;

-   maxdepth = 6
-   minsplit = 80
-   minbucket = eliminated

<br>

```{r pre pruning  meaningful emp ne grad year 10, echo=TRUE}
# Grow a tree with minsplit of 40 and max depth of 10
meaningful.emp.ne.grad.year.10.model.preprune <- rpart(grad.year.10 ~ ., data = train, method = "class", 
                   control = rpart.control(cp = 0, maxdepth = 6, minsplit = 80))

```

```{r pre pruning summary meaningful emp ne grad year 10, include=FALSE}

#Summary
summary(meaningful.emp.ne.grad.year.10.model.preprune)
```

```{r pre pruning plot meaningful emp ne grad year 10, echo=TRUE}
#Plot tree
rpart.plot(meaningful.emp.ne.grad.year.10.model.preprune)

# Examine the complexity plot
printcp(meaningful.emp.ne.grad.year.10.model.preprune)
plotcp(meaningful.emp.ne.grad.year.10.model.preprune)


# Compute the accuracy of the pruned tree

test$pred <- predict(meaningful.emp.ne.grad.year.10.model.preprune, test, type = "class")

accuracy_preprun <- mean(test$pred == test$grad.year.10)

accuracy_preprun

```

<br>

The pre-pruning resulted in a significantly less complex tree with a .8341776 accuracy. Let's see what variables are important in this model.

-   ps.grad.location: In region
    -   No: 85% probability that the student will have meaningful employment in the region
    -   Yes
        -   Dem_Desc
        -   total.cte.courses \>= 7

Variable importance shows the following;

-   Most important
    -   ps.grad.location
    -   ps.grad.InsitutionSector
    -   highest.cred.level
    -   Dem_Desc
    -   total.cte.courses.taken
-   Variables that are missing
    -   Demographics: All
        -   grad.year.covid
        -   economic.status
        -   SpecialEdStauts
        -   RaceEthnicity
        -   english.learner
    -   High school characteristics
        -   range.school
    -   Prep for post-secondary: All
        -   pseo.participant
        -   took.ACT
        -   ACTCompositeScore
        -   MCA.M
        -   MCA.R
        -   MCA.S
    -   CTE Engagement
        -   cte.achievement
    -   Post-secondary path
        -   ps.grad

<br>

```{r pre pruning variable importance meaningful emp ne grad year 10, echo=TRUE}
meaningful.emp.ne.grad.year.10.model.preprune$variable.importance


importance <- meaningful.emp.ne.grad.year.10.model.preprune$variable.importance

importance <- sort(importance, decreasing = TRUE)

barplot(importance,
        main = "Variable Importance",
        xlab = "Variables",
        ylab = "Importance",
        col = "steelblue",
        las = 2,        # make axis labels vertical
        cex.names = 0.8) # smaller font if needed
```

<br>

### Post-pruning

Next, let's try postpruning. The idea here is to allow the decision tree to grow fully and observe the CP value. Next, we prune/cut the tree with the optimal CP value as the parameter as shown in below code.

We will start out by using the optimal method which is just choosing the cp value with the lowest xerror from the base model.

<br>

```{r postpruning meaningful emp ne grad year 10, echo=TRUE}
cp_table <- meaningful.emp.ne.grad.year.10.model$cptable

min_xerror <- min(cp_table[, "xerror"])
min_xerror_se <- cp_table[which.min(cp_table[,"xerror"]), "xstd"]

threshold <- min_xerror + min_xerror_se

one_se_index <- which(cp_table[, "xerror"] <= threshold)[1] 

cp_1se <- cp_table[one_se_index, "CP"]

optimal_cp <- meaningful.emp.ne.grad.year.10.model$cptable[which.min(meaningful.emp.ne.grad.year.5.model$cptable[, "xerror"]), "CP"]

# Prune the hr_base_model based on the optimal cp value
meaningful.emp.ne.grad.year.10.model.postprune <- prune(meaningful.emp.ne.grad.year.10.model, cp = optimal_cp)

#Summary
summary(meaningful.emp.ne.grad.year.10.model.postprune)

#Plot tree
rpart.plot(meaningful.emp.ne.grad.year.10.model.postprune)

# Examine the complexity plot
printcp(meaningful.emp.ne.grad.year.10.model.postprune)
plotcp(meaningful.emp.ne.grad.year.10.model.postprune)


# Compute the accuracy of the pruned tree

test$pred <- predict(meaningful.emp.ne.grad.year.10.model.postprune, test, type = "class")

accuracy_postprun <- mean(test$pred == test$grad.year.10)

accuracy_postprun

```

<br>

The accuracy is still a bit lower than pre-pruning - .8336711

We end up with a bit more of a complicated tree. Here are the important paths

-   ps.grad.location: In region
    -   No: 83% probability individual has no meaningful employment in region
    -   Yes
        -   Dem_Desc
        -   range.school
        -   total.cte.courses.taken
        -   ACTCompositeScore
        -   MCA.M
        -   took.ACT
        -   SpecialEdStatus
        -   pseo.participant

Importance of variables are;

-   Most important
    -   Post-secondary pathway
        -   ps.grad.location
        -   ps.grad.InstitutionSector
        -   highest.cred.level
    -   total.cte.courses.taken
    -   Dem_Desc
    -   range.school
-   Less important
    -   Prep for post-secondary
        -   MCA.M
        -   ACTCompositeScore
        -   MCA.R
        -   took.ACT
-   Not important
    -   english.learner
    -   pseo.participant
    -   cte.achievement
    -   economic.status
    -   MCA.S
    -   RaceEthnicity
-   Missing data
    -   grad.year.covid
    -   ps.grad

<br>

```{r post pruning variable importance meaningful emp ne grad year 10, echo=TRUE}
meaningful.emp.ne.grad.year.10.model.postprune$variable.importance

importance <- meaningful.emp.ne.grad.year.10.model.postprune$variable.importance

importance <- sort(importance, decreasing = TRUE)

barplot(importance,
        main = "Variable Importance",
        xlab = "Variables",
        ylab = "Importance",
        col = "steelblue",
        las = 2,        # make axis labels vertical
        cex.names = 0.8) # smaller font if needed

```

<br>

Now let's compare the accuracy. The prepruned tree/model looks to be the best.

```{r compare accuracy meaningful emp ne grad year 10, echo=TRUE}
data.frame(base_accuracy, accuracy_preprun, accuracy_postprun)

```

### Summary

Overall, the variables that were the most consistently important throughout the analysis were the following;

The pre-pruning resulted in a significantly less complex tree with a .8341776 accuracy. Let's see what variables are important in this model.

Variable importance shows the following;

-   Most important
    -   Nearly all of the post-secondary paths
        -   ps.grad.location
        -   ps.grad.InsitutionSector
        -   highest.cred.level
    -   One high school characteristics
        -   Dem_Desc
    -   One CTE engagement
        -   total.cte.courses.taken
-   Variables that are missing
    -   Demographics: All
        -   grad.year.covid
        -   economic.status
        -   SpecialEdStauts
        -   RaceEthnicity
        -   english.learner
    -   High school characteristics
        -   range.school
    -   Prep for post-secondary: All
        -   pseo.participant
        -   took.ACT
        -   ACTCompositeScore
        -   MCA.M
        -   MCA.R
        -   MCA.S
    -   CTE Engagement
        -   cte.achievement
    -   Post-secondary path
        -   ps.grad

<br>

# Summary across time

## One year after graduating high school

Every single variable related to pathways after high school were very important in whether someone had meaningful employment in the region. Somewhat important were nearly all of the demographic variables, a couple of variables for post-secondary prep.

+-------------------------+----------------------------+------------------+-------------------------+
| Variable group          | Most important             | Maybe important  | Missing                 |
+=========================+============================+==================+=========================+
| Post-secondary pathways | ps.grad.location,          |                  |                         |
|                         |                            |                  |                         |
|                         | ps.grad.InstitutionSector, |                  |                         |
|                         |                            |                  |                         |
|                         | highest.cred.level,        |                  |                         |
|                         |                            |                  |                         |
|                         | ps.grad                    |                  |                         |
+-------------------------+----------------------------+------------------+-------------------------+
| Demographics            |                            | RaceEthnicity,   | economic.status         |
|                         |                            |                  |                         |
|                         |                            | SpecialEdStatus, |                         |
|                         |                            |                  |                         |
|                         |                            | english.learner, |                         |
|                         |                            |                  |                         |
|                         |                            | grad.year.covid  |                         |
+-------------------------+----------------------------+------------------+-------------------------+
| Prep for post-secondary |                            | took.ACT,        | pseo.participant,       |
|                         |                            |                  |                         |
|                         |                            | MCA.R            | ACTCompositeScore,      |
|                         |                            |                  |                         |
|                         |                            |                  | MCA.M,                  |
|                         |                            |                  |                         |
|                         |                            |                  | MCA.S                   |
+-------------------------+----------------------------+------------------+-------------------------+
| Location of high school |                            |                  | Dem_Desc,               |
|                         |                            |                  |                         |
|                         |                            |                  | range.school            |
+-------------------------+----------------------------+------------------+-------------------------+
| CTE Engagement          |                            |                  | cte.achievement,        |
|                         |                            |                  |                         |
|                         |                            |                  | total.cte.courses.taken |
+-------------------------+----------------------------+------------------+-------------------------+

<br>

## Five year after graduating high school

Every single variable related to pathways after high school were very important in whether someone had meaningful employment in the region. In addition, the rurality of an individual's high school and whether they were located on the range moved up to being very important.

+-------------------------+----------------------------+------------------+-------------------------+
| Variable group          | Most important             | Maybe important  | Missing                 |
+=========================+============================+==================+=========================+
| Post-secondary pathways | ps.grad.location,          |                  |                         |
|                         |                            |                  |                         |
|                         | ps.grad.InstitutionSector, |                  |                         |
|                         |                            |                  |                         |
|                         | highest.cred.level,        |                  |                         |
|                         |                            |                  |                         |
|                         | ps.grad                    |                  |                         |
+-------------------------+----------------------------+------------------+-------------------------+
| Demographics            |                            | RaceEthnicity,   | economic.status,        |
|                         |                            |                  |                         |
|                         |                            | SpecialEdStatus, | grad.year.covid         |
|                         |                            |                  |                         |
|                         |                            | english.learner  |                         |
+-------------------------+----------------------------+------------------+-------------------------+
| Prep for post-secondary |                            | took.ACT,        | pseo.participant,       |
|                         |                            |                  |                         |
|                         |                            | MCA.R,           | ACTCompositeScore,      |
|                         |                            |                  |                         |
|                         |                            | MCA.M            | MCA.S                   |
+-------------------------+----------------------------+------------------+-------------------------+
| Location of high school | Dem_Desc,                  |                  |                         |
|                         |                            |                  |                         |
|                         | range.school               |                  |                         |
+-------------------------+----------------------------+------------------+-------------------------+
| CTE Engagement          |                            |                  | cte.achievement,        |
|                         |                            |                  |                         |
|                         |                            |                  | total.cte.courses.taken |
+-------------------------+----------------------------+------------------+-------------------------+

```{r master after analysis}
master.after.CART <- master %>%
  select(-grad.year.covid, -economic.status, -SpecialEdStatus, -english.learner, -pseo.participant, -took.ACT, -MCA.S)

write_csv(master.after.CART, "Data/SLEDS/Masters/After analysis/Master-after-CART.csv")

```
