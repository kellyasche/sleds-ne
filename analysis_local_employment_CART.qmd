---
title: "Local Employment CART Analysis"
editor: visual
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
library(tidyverse)
library(sf)
library(ggrepel)
library(scales)
library(shiny)
library(shinycssloaders)
library(ggiraph)
library(kableExtra)
library(rmapshaper)
library(cowplot)
library(DT)
library(htmlwidgets)
library(RColorBrewer)
library(readxl)
library(janitor)
library(lubridate)
library(systemfonts)
reset_font_cache()
library(ggtext)
library(gmodels)
library(fastDummies)
library(car)
library(glmnet)
library(glmnetUtils)
library(pscl)
library(sjPlot)
library(rpart)
library(rpart.plot)
```

```{r themes and shapefiles, include=FALSE}
theme_bar <- theme_bw() +
  theme(panel.grid.major = element_line(color = "grey70", linewidth  = 0.1),
        panel.grid.minor = element_blank(),
        axis.ticks = element_blank(),
        axis.text = element_text(face = "bold"),
        panel.border = element_blank(),
        legend.background = element_rect(fill = "transparent", color = "transparent"),
        legend.key = element_rect(fill = "transparent"),
        legend.key.size = unit(1, "lines"),
        legend.margin = margin(0,0,0,0),
        legend.title = element_blank(),
        legend.text = element_text(margin = margin(l = 2)),
        text = element_text(family = "Arial") ,
        plot.title.position = "plot",
        plot.title = element_text(face = "bold"))

theme_line <- theme_bw() +
  theme(legend.background = element_rect(fill = "transparent", color = "transparent"),
        legend.key = element_rect(fill = "transparent"),
        legend.text = element_text(margin = margin(l = 2)),
        panel.grid.minor = element_blank(),
        panel.grid.major = element_line(color = "grey70", linewidth = 0.1),
        axis.ticks = element_blank(),
        axis.text = element_text(face = "bold"),
        panel.border = element_blank(),
        legend.margin = margin(0,0,0,0),
        legend.key.size = unit(1, "lines"),
        text = element_text(family = "Arial") ,
        plot.title.position = "plot",
        plot.title = element_text(face = "bold"))


theme_sf <- theme_bw() +
  theme(axis.text.x=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks=element_blank(),
        panel.background = element_blank(),
        panel.grid.major = element_line(color = "white"),
        panel.border = element_blank(),
        legend.title = element_blank(),
        legend.text = element_text(margin = margin(l = 2)),
        legend.margin = margin(0,0,0,0),
        legend.key.size = unit(1, "lines"),
        text = element_text(family = "Arial") ,
        plot.title.position = "plot",
        plot.title = element_text(face = "bold"))

regions <- read_csv("/Users/kellyasche/Library/CloudStorage/GoogleDrive-kasche@ruralmn.org/My Drive/Data Prep/R Projects/Join docs/county_regions.csv") %>%
    select(5,6) %>%
    unique() %>%
    mutate(edr = str_replace(edr, "  ", " "),
           planning.region = str_replace(planning.region, " Minnesota", ""),
           planning.region = fct_relevel(planning.region, "Northwest", "Northeast", "Central", "Seven County Mpls-St Paul", "Southwest", "Southeast"),
           edr = fct_relevel(edr, "EDR 1 - Northwest", "EDR 2 - Headwaters", "EDR 3 - Arrowhead", "EDR 4 - West Central", "EDR 5 - North Central", "EDR 6E- Southwest Central", "EDR 6W- Upper Minnesota Valley", "EDR 7E- East Central", "EDR 7W- Central", "EDR 8 - Southwest", "EDR 9 - South Central", "EDR 10 - Southeast", "EDR 11 - 7 County Twin Cities", "Minnesota"))

counties.regions <- read_csv("/Users/kellyasche/Library/CloudStorage/GoogleDrive-kasche@ruralmn.org/My Drive/Data Prep/R Projects/Join docs/county_regions.csv") %>%
  rename(mif = `MIF Region`) %>%
  mutate(countyfp = formatC(countyfp, width = 3, flag = "0"),
         Name = str_to_title(Name),
         Name = str_replace(Name, "Q", "q"),
         Name = str_replace(Name, "Of The", "of the"),
         Name = str_replace(Name, "Mcleod", "McLeod"),
         Dem_Desc = ifelse(Name == "Minnesota", "Minnesota", Dem_Desc) ,
         edr = str_replace(edr, "  ", " "),
         planning.region = str_replace(planning.region, " Minnesota", ""),
         planning.region = fct_relevel(planning.region, "Northwest", "Northeast", "Central", "Seven County Mpls-St Paul", "Southwest", "Southeast"),
         edr = fct_relevel(edr, "EDR 1 - Northwest", "EDR 2 - Headwaters", "EDR 3 - Arrowhead", "EDR 4 - West Central", "EDR 5 - North Central", "EDR 6E- Southwest Central", "EDR 6W- Upper Minnesota Valley", "EDR 7E- East Central", "EDR 7W- Central", "EDR 8 - Southwest", "EDR 9 - South Central", "EDR 10 - Southeast", "EDR 11 - 7 County Twin Cities", "Minnesota"),
         mif = ifelse(is.na(mif), "TC", mif),
         mif = as.factor(mif),
         mif = fct_relevel(mif, "NW", "NE", "WC", "EC", "SW", "SE", "TC"),
Dem_Desc = fct_relevel(Dem_Desc, "Entirely rural", "Town/rural mix", "Urban/town/rural mix", "Entirely urban"))


color.ruca <- c("Entirely rural" = "#009933", "Town/rural mix" = "#99CC33", "Urban/town/rural mix" = "#CC9966", "Entirely urban" = "#754C29", "Minnesota" = "black")

color.pr <- c("Northwest" = 	"#4575b4", "Northeast" = "grey", "Central" = "#fee090", "Seven County Mpls-St Paul" = "#d73027", "Southwest" = "#91bfdb", "Southeast" = "#fc8d59", "Minnesota" = "black")

color.edr <- c("EDR 1 - Northwest" = "#b3cde3", "EDR 2 - Headwaters" = "#8c96c6", "EDR 3 - Arrowhead" = "#fe9929", "EDR 4 - West Central" = "#8856a7", "EDR 5 - North Central" = "#810f7c", "EDR 6E- Southwest Central" = "#e5f5f9", "EDR 6W- Upper Minnesota Valley" = "#bdc9e1", "EDR 7E- East Central" = "#99d8c9", "EDR 7W- Central" = "#2ca25f", "EDR 8 - Southwest" = "#74a9cf", "EDR 9 - South Central" = "#0570b0", "EDR 10 - Southeast" = "#d7301f", "EDR 11 - 7 County Twin Cities" = "#d8b365", "Minnesota" = "black")

color.edr.simple <- c("EDR 1" = "#b3cde3", "EDR 2" = "#8c96c6", "EDR 3" = "#fe9929", "EDR 4" = "#8856a7", "EDR 5" = "#810f7c", "EDR 6E" = "#e5f5f9", "EDR 6W" = "#bdc9e1", "EDR 7E" = "#99d8c9", "EDR 7W" = "#2ca25f", "EDR 8" = "#74a9cf", "EDR 9" = "#0570b0", "EDR 10" = "#d7301f", "EDR 11" = "#d8b365", "Minnesota" = "black")

color.pr.edr <- c ("Northwest" = "#4575b4","Northeast" = "#e0f3f8", "Central" = "#fee090", "Seven County Mpls-St Paul" = "#d73027", "Southwest" = "#91bfdb", "Southeast" = "#fc8d59", "Minnesota" = "black", "EDR 1 - Northwest" = "#b3cde3", "EDR 2 - Headwaters" = "#8c96c6", "EDR 3 - Arrowhead" = "#fe9929", "EDR 4 - West Central" = "#8856a7", "EDR 5 - North Central" = "#810f7c", "EDR 6E- Southwest Central" = "#e5f5f9", "EDR 6W- Upper Minnesota Valley" = "#bdc9e1", "EDR 7E- East Central" = "#99d8c9", "EDR 7W- Central" = "#2ca25f", "EDR 8 - Southwest" = "#74a9cf", "EDR 9 - South Central" = "#0570b0", "EDR 10 - Southeast" = "#d7301f", "EDR 11 - 7 County Twin Cities" = "#d8b365")

mn_counties <- st_read("/Users/kellyasche/Library/CloudStorage/GoogleDrive-kasche@ruralmn.org/My Drive/Data Prep/R Projects/Shapefiles/County shapefiles/MNCounties_MNDOT.shp", quiet = TRUE) %>%
  ms_simplify(keep = .01, keep_shapes = TRUE) %>%
  rename(countyfp = FIPS_CODE)
```

```{r master dataset}

original <- read_csv("Data/SLEDS/Masters/After analysis/Master-after-ct.csv")

kable(head(original))

kable(names(original))
```

```{r joining masters}
master <- original %>%
  mutate_at(2:17, as.factor) %>%
  mutate_at(23:25, as.factor) %>%
  mutate(grad.year.1 = fct_relevel(grad.year.1, "Meaningful emp NE", "Meaningful emp MN", "Attending ps", "Not meaningful, not attending ps", "No MN emp record, not attending ps", "After 2023"),
         grad.year.5 = fct_relevel(grad.year.5, "Meaningful emp NE", "Meaningful emp MN", "Attending ps", "Not meaningful, not attending ps", "No MN emp record, not attending ps", "After 2023"),
         grad.year.10 = fct_relevel(grad.year.10, "Meaningful emp NE", "Meaningful emp MN", "Attending ps", "Not meaningful, not attending ps", "No MN emp record, not attending ps", "After 2023")) %>%
  droplevels()

```

<br>

We will use a tree-based method for classification - CART analysis. This type of analysis involves stratifying and/or segmenting the predictor space into a number of simple regions. Essentially, it's another way to see which independent variables play a role in if an individual has meaningful employment in the local region X. We will be using the independent variables that were identified as being important in the multiple correspondence analysis.

There are a number of states at which we categorize individuals in the dataset;

1.  Has meaningful employment in the Northeast region.
2.  Has meaningful employment in Minnesota, but not in Northeast Minnesota.
3.  Is attending post-secondary.
4.  Has a MN employment record but it's not meaningful, and not attending post-secondary.
5.  Does not have a MN employment record and is not attending post-secondary.

There are three "times" in which we checked to see if the individual had meaningful employment within these geographies;

1.  one year after graduating high school
2.  five years after graduation, and
3.  ten years after graduation.

Meaningful employment is determined by whether an individual worked 1,000 hours for an employer during time X. In addition, if the individual is working for an employer but not meaningful at time X but worked 1,000 hours for that employer during another year it's still considered "meaningful".

Due to time x potentially being passed the date of the latest data (2023) for some individuals, the analysis below will filter out all individuals where time x is after 2023.

The primary independent variables that the cross tables indicated as important are;

```{r list of ind var}
ind.var <- master %>%
  select(-PersonID, -grad.year.1, -grad.year.5, -grad.year.10)
  
ind.var.names <- ind.var %>%
  names()

ind.var %>%
  lapply(class)
```

<br>

# Methodology

We are going to use CART/Decision Trees to see which independent variables are important. One limitation of this method is that the dependent variable must be binary. So, we will need to force our 5 states into 2 states. We will begin by doing the following;

1.  Meaningful emp in SW: this will include the following categories for each time.x;

-   Meaningful emp in region

2.  No meaningful emp in SW: this will include the following categories for each time.x:

-   Meaningful emp MN
-   Attending ps
-   Not meaningful, not attending ps
-   No MN emp record, not attending ps

Once we look at this analysis, we can determine if we want to split the binary differently for further analysis.

<br>

# Meaningful emp in NE

First, let's re-categorize the dependent variables so that they are binary.

<br>

```{r prep meaningful emp in ne, echo=TRUE}

meaningful.emp.ne <- master %>%
  mutate(grad.year.1 = ifelse(grad.year.1 %in% c("Meaningful emp NE"), "Meaningful emp NE", 
                              ifelse(grad.year.1 %in% c("Meaningful emp MN", "Not meaningful, not attending ps", "No MN emp record, not attending ps"), "No meaningful emp NE",
                                     ifelse(grad.year.1 == "After 2023", "After 2023",
                                            ifelse(grad.year.1 == "Attending ps", "Attending ps", as.character(grad.year.1))))),
         grad.year.1 = as.factor(grad.year.1),
         grad.year.5 = ifelse(grad.year.5 %in% c("Meaningful emp NE"), "Meaningful emp NE", 
                              ifelse(grad.year.5 %in% c("Meaningful emp MN", "Not meaningful, not attending ps", "No MN emp record, not attending ps"), "No meaningful emp NE",
                                     ifelse(grad.year.5 == "After 2023", "After 2023",
                                            ifelse(grad.year.5 == "Attending ps", "Attending ps", as.character(grad.year.5))))),
         grad.year.5 = as.factor(grad.year.5),
         grad.year.10 = ifelse(grad.year.10 %in% c("Meaningful emp NE"), "Meaningful emp NE", 
                              ifelse(grad.year.10 %in% c("Meaningful emp MN", "Not meaningful, not attending ps", "No MN emp record, not attending ps"), "No meaningful emp NE",
                                     ifelse(grad.year.10 == "After 2023", "After 2023",
                                            ifelse(grad.year.10 == "Attending ps", "Attending ps", as.character(grad.year.10))))),
         grad.year.10 = as.factor(grad.year.10),
         grad.year.1 = fct_relevel(grad.year.1, "Meaningful emp NE", "No meaningful emp NE", "Attending ps", "After 2023"),
         grad.year.5 = fct_relevel(grad.year.5, "Meaningful emp NE", "No meaningful emp NE", "Attending ps", "After 2023"),
         grad.year.10 = fct_relevel(grad.year.10, "Meaningful emp NE", "No meaningful emp NE", "Attending ps", "After 2023"))

```

<br>

## One year after graduation

Since our dependent variable includes a state in which someone is attending post-secondary and the post-secondary variables are related to an individual finishing post-secondary, we will remove "ps.grad.InstitutionSector" and the "highest.cred.level" variable from the analysis.

```{r prep meaningful emp SW grad year 1}
meaningful.emp.ne.grad.year.1 <- meaningful.emp.ne %>%
  filter(grad.year.1 != "After 2023") %>%
  filter(grad.year.1 != "Attending ps") %>%
  select(-PersonID, -grad.year.5, -grad.year.10)

kable(names(meaningful.emp.ne.grad.year.1))
```

### Base model

First we will split the data into two sets, Train and Test, in a 70:30 ratio. The Train set is used for training and creating the model. The Test set is considered to be a dummy production environment to test predictions and evaluate the accuracy of the model.

<br>

```{r split dataset into test and train meaningful emp NE grad year 1, echo=TRUE}
set.seed(1234)

sample_ind <- sample(nrow(meaningful.emp.ne.grad.year.1), nrow(meaningful.emp.ne.grad.year.1) *.7)

train <- meaningful.emp.ne.grad.year.1[sample_ind,]

test <- meaningful.emp.ne.grad.year.1[-sample_ind,]

```

<br>

Next, we create a decision tree model by calling the rpart function. Let's first create a base model with default parameters and value. The CP (complexity parameter) is used to control tree growth. If the cost of adding a variable is higher then the value of CP, then tree growth stops.

<br>

```{r create decision tree meaningful emp NE grad year 1, echo=TRUE, include = FALSE}
#Base model

meaningful.emp.ne.grad.year.1.model <- rpart(grad.year.1 ~ ., data = train, method = "class", control = rpart.control(cp = 0))

#Summary
summary(meaningful.emp.ne.grad.year.1.model)

```

```{r decision tree plot meaningful emp NE grad year 1}
#Plot tree
rpart.plot(meaningful.emp.ne.grad.year.1.model)

# Examine the complexity plot
printcp(meaningful.emp.ne.grad.year.1.model)

plotcp(meaningful.emp.ne.grad.year.1.model)

```

<br>

The resulting model produced a VERY complex tree with too many nodes that it isn't interpretable. However, examining the complexity parameters shows that I have an increasing cross-validated error which provides evidence of a decision tree with too much complexity.

Below are the values in variable importance and there are a couple of themes of importance;

1.  post-secondary pathway
2.  cte involvment
3.  Prep for post-secondary
4.  demographics, range school,

<br>

```{r base model variable importance meaningful emp NE grad year 1, echo=TRUE}

meaningful.emp.ne.grad.year.1.model$variable.importance

```

Next, the accuracy of the model is computed and stored in a variable base_accuracy so we can compare it to our pruned trees later.

<br>

```{r model accuracy meaningful emp NE grad year 1, echo=TRUE}
test$pred <- predict(meaningful.emp.ne.grad.year.1.model, test, type = "class")

base_accuracy <- mean(test$pred == test$grad.year.1)

base_accuracy

```

<br>

### Pre-pruning

Next, we need to prune. We can either pre-prune or post-prune. We will start with pre-pruning and use each method - max depth, min depth, and min bucket.

<br>

```{r pre pruning  meaningful emp NE grad year 1, echo=TRUE}
# Grow a tree with minsplit of 40 and max depth of 10
meaningful.emp.ne.grad.year.1.model.preprune <- rpart(grad.year.1 ~ ., data = train, method = "class", 
                   control = rpart.control(cp = 0, maxdepth = 5, minsplit = 30))

```

```{r pre pruning summary meaningful emp NE grad year 1, include=FALSE}

#Summary
summary(meaningful.emp.ne.grad.year.1.model.preprune)
```

```{r pre pruning plot meaningful emp NE grad year 1, echo=TRUE}
#Plot tree
rpart.plot(meaningful.emp.ne.grad.year.1.model.preprune)

# Examine the complexity plot
printcp(meaningful.emp.ne.grad.year.1.model.preprune)
plotcp(meaningful.emp.ne.grad.year.1.model.preprune)


# Compute the accuracy of the pruned tree

test$pred <- predict(meaningful.emp.ne.grad.year.1.model.preprune, test, type = "class")

accuracy_preprun <- mean(test$pred == test$grad.year.1)

accuracy_preprun
```

The pre-pruning resulted in a significantly less complex tree with a .827 accuracy. Let's see what variables are important in this model.

The primary nodes are;

1.  ps.grad.location
    -   in-region
2.  highest.cred.level
    -   Associate degree \| Bachelor degree
3.  ps.grad
    -   Attending ps
4.  range.school
    -   range school
5.  RaceEthnicity
    -   AI, Unknown, white
6.  total.cte.courses
    -   the more the better
7.  Gender
8.  MCA.M

Overall, these are the most important themes;

1.  post-secondary pathway is still very important
2.  RaceEthnicity: a few demographic variables jump up in importance
3.  range.school
4.  CTE
5.  preparations for post-secondary pathway are still important.
6.  Missing:
    -   ACTCompositeScore
    -   MCA.S,
    -   economic.status
    -   took.ACT
    -   pseo.participant,
    -   ap.exam

<br>

```{r pre pruning variable importance meaningful emp SW grad year 1, echo=TRUE}
meaningful.emp.ne.grad.year.1.model.preprune$variable.importance
```

<br>

### Post-pruning

Next, let's try postpruning. The idea here is to allow the decision tree to grow fully and observe the CP value. Next, we prune/cut the tree with the optimal CP value as the parameter as shown in below code:

<br>

```{r postpruning meaningful emp NE grad year 1, echo=TRUE}

cp_table <- meaningful.emp.ne.grad.year.1.model$cptable

min_xerror <- min(cp_table[, "xerror"])
min_xerror_se <- cp_table[which.min(cp_table[,"xerror"]), "xstd"]

threshold <- min_xerror + min_xerror_se

one_se_index <- which(cp_table[, "xerror"] <= threshold)[1] 

cp_1se <- cp_table[one_se_index, "CP"]

# Prune the hr_base_model based on the optimal cp value
meaningful.emp.ne.grad.year.1.model.postprune <- prune(meaningful.emp.ne.grad.year.1.model, cp = cp_1se)

#Summary
summary(meaningful.emp.ne.grad.year.1.model.postprune)

#Plot tree
rpart.plot(meaningful.emp.ne.grad.year.1.model.postprune, nn = TRUE)

# Examine the complexity plot
printcp(meaningful.emp.ne.grad.year.1.model.postprune)
plotcp(meaningful.emp.ne.grad.year.1.model.postprune)


# Compute the accuracy of the pruned tree

test$pred <- predict(meaningful.emp.ne.grad.year.1.model.postprune, test, type = "class")

accuracy_postprun <- mean(test$pred == test$grad.year.1)

accuracy_postprun

```

<br>

We now have a very simple tree, that might be a little too simple. Big piece, though, is that 91% of the individuals that did not graduate from college in the region did not have meaningful employment in Northeast.

It tells me the following;

-   post-secondary pathways
    -   ps.grad.location
    -   ps.grad.InstitutionSector
    -   highest.cred.level
    -   ps.grad
-   Demographics
    -   SpecialEdStatus
    -   english.learner
    -   grad.year.covid
-   post-secondary prep
-   Missing from base run
    -   CTE stuff
    -   Gender
    -   RaceEthnicity
    -   

<br>

```{r post pruning variable importance meaningful emp SW grad year 1, echo=TRUE}
meaningful.emp.ne.grad.year.1.model.postprune$variable.importance

importance <- meaningful.emp.ne.grad.year.1.model.postprune$variable.importance

importance <- sort(importance, decreasing = TRUE)

barplot(importance,
        main = "Variable Importance",
        xlab = "Variables",
        ylab = "Importance",
        col = "steelblue",
        las = 2,        # make axis labels vertical
        cex.names = 0.8 # smaller font if needed
)
```

<br>

Now let's compare the accuracy. The pre-pruned tree does get a bit better accuracy.

```{r compare accuracy meaningful emp NE grad year 1, echo=TRUE}
data.frame(base_accuracy, accuracy_preprun, accuracy_postprun)

```

### Summary

The variable importance across the models do not vary much. The most consistent variables that were high in the importance values were;

-   Post-secondary pathway
    -   ps.grad.location
    -   ps.grad.InstitutionSector
    -   highest.cred.level
    -   ps.grad
-   CTE engagement
-   range.school
-   RaceEthnicity
-   College prepwork
    -   took.ACT
    -   ACTCompositeScore
    -   MCA.M
    -   MCA.R
-   Other demographics

<br>

## Five years after graduation

Next we will look at the variables importance at five years after graduation. At this point we will bring back the post-secondary variables.

```{r prep meaningful emp NE grad year 5}
meaningful.emp.ne.grad.year.5 <- meaningful.emp.ne %>%
  filter(grad.year.5 != "After 2023") %>%
  filter(grad.year.5 != "Attending ps") %>%
  droplevels() %>%
  select(-PersonID, -grad.year.1, -grad.year.10)

kable(names(meaningful.emp.ne.grad.year.5))
```

### Base model

First we will split the data into two sets, Train and Test, in a 70:30 ratio. The Train set is used for training and creating the model. The Test set is considered to be a dummy production environment to test predictions and evaluate the accuracy of the model.

<br>

```{r split dataset into test and train meaningful emp NE grad year 5, echo=TRUE}
set.seed(1234)

sample_ind <- sample(nrow(meaningful.emp.ne.grad.year.5), nrow(meaningful.emp.ne.grad.year.5) *.7)

train <- meaningful.emp.ne.grad.year.5[sample_ind,]

test <- meaningful.emp.ne.grad.year.5[-sample_ind,]
```

Next, we create a decision tree model by calling the rpart function. Let's first create a base model with default parameters and value. The CP (complexity parameter) is used to control tree growth. If the cost of adding a variable is higher then the value of CP, then tree growth stops.

<br>

```{r create decision tree meaningful emp NE grad year 5, echo=TRUE, include = FALSE}
#Base model

meaningful.emp.ne.grad.year.5.model <- rpart(grad.year.5 ~ ., data = train, method = "class", cp = 0)

#Summary
summary(meaningful.emp.ne.grad.year.5.model)

```

```{r decision tree plot meaningful emp ne grad year 5}
#Plot tree
rpart.plot(meaningful.emp.ne.grad.year.5.model)

# Examine the complexity plot
printcp(meaningful.emp.ne.grad.year.5.model)

plotcp(meaningful.emp.ne.grad.year.5.model)

```

<br>

The resulting model produced a VERY complex tree with too many nodes that it isn't interpretable. However, examining the complexity parameters shows that I have an increasing cross-validated error which provides evidence of a decision tree with too much complexity.

Below are the values in variable important and there are a couple of themes;

1.  Post-secondary pathway are significant
2.  CTE engagement is significant
3.  Post-secondary prep work is significant
4.  range.school is important
5.  Demographics are a bit lower
6.  Difference from grad.year.1
    1.  ps.grad isn't as significant.

<br>

```{r base model variable importance meaningful emp ne grad year 5, echo=TRUE}

meaningful.emp.ne.grad.year.5.model$variable.importance

```

Next, the accuracy of the model is computed and stored in a variable base_accuracy so we can compare it to our pruned trees later.

<br>

```{r model accuracy meaningful emp ne grad year 5, echo=TRUE}
test$pred <- predict(meaningful.emp.ne.grad.year.5.model, test, type = "class")

base_accuracy <- mean(test$pred == test$grad.year.5)

base_accuracy
```

### Pre-pruning

Next, we need to prune. We can either pre-prune or post-prune. We will start with pre-pruning and use each method - max depth, min depth, and min bucket.

<br>

```{r pre pruning  meaningful emp ne grad year 5, echo=TRUE}
# Grow a tree with minsplit of 40 and max depth of 10
meaningful.emp.ne.grad.year.5.model.preprune <- rpart(grad.year.5 ~ ., data = train, method = "class", 
                   control = rpart.control(cp = 0, maxdepth = 6, minsplit = 70))

```

```{r pre pruning summary meaningful emp ne grad year 5, include=FALSE}

#Summary
summary(meaningful.emp.ne.grad.year.5.model.preprune)
```

```{r pre pruning plot meaningful emp ne grad year 5, echo=TRUE}
#Plot tree
rpart.plot(meaningful.emp.ne.grad.year.5.model.preprune)

# Examine the complexity plot
printcp(meaningful.emp.ne.grad.year.5.model.preprune)
plotcp(meaningful.emp.ne.grad.year.5.model.preprune)


# Compute the accuracy of the pruned tree

test$pred <- predict(meaningful.emp.ne.grad.year.5.model.preprune, test, type = "class")

accuracy_preprun <- mean(test$pred == test$grad.year.5)

accuracy_preprun
```

The pre-pruning resulted in a significantly less complex tree with a .807 accuracy. Let's see what variables are important in this model.

The primary nodes are;

1.  ps.grad.location
    -   graduating from an institution outside of region has large impact on whether they have meaningful employment in region.
2.  range.school
3.  Dem_Desc
4.  cte engagement
5.  SpecialEdStatus
6.  MCA.M

Primary variable themes are;

-   Post-secondary pathway
-   range.school & Dem_Desc
-   CTE engagement still important
-   a few demographics such as RaceEthnicity, english.learner, Gender and SpecialEdStatus
-   Missing from previous
    -   economic.status
    -   ap.exam
    -   ACTCompositeScore
    -   MCA.S
    -   economic.status
    -   pseo.participant
    -   ap.exam

<br>

```{r pre pruning variable importance meaningful emp ne grad year 5, echo=TRUE}
meaningful.emp.ne.grad.year.5.model.preprune$variable.importance
```

### Post-pruning

Next, let's try postpruning. The idea here is to allow the decision tree to grow fully and observe the CP value. Next, we prune/cut the tree with the optimal CP value as the parameter as shown in below code:

<br>

```{r postpruning meaningful emp ne grad year 5, echo=TRUE}
cp_table <- meaningful.emp.ne.grad.year.5.model$cptable

min_xerror <- min(cp_table[, "xerror"])
min_xerror_se <- cp_table[which.min(cp_table[,"xerror"]), "xstd"]

threshold <- min_xerror + min_xerror_se

one_se_index <- which(cp_table[, "xerror"] <= threshold)[1] 

cp_1se <- cp_table[one_se_index, "CP"]

# Prune the hr_base_model based on the optimal cp value
meaningful.emp.ne.grad.year.5.model.postprune <- prune(meaningful.emp.ne.grad.year.5.model, cp = .00081911)

#Summary
summary(meaningful.emp.ne.grad.year.5.model.postprune)

#Plot tree
rpart.plot(meaningful.emp.ne.grad.year.5.model.postprune)

# Examine the complexity plot
printcp(meaningful.emp.ne.grad.year.5.model.postprune)
plotcp(meaningful.emp.ne.grad.year.5.model.postprune)


# Compute the accuracy of the pruned tree

test$pred <- predict(meaningful.emp.ne.grad.year.5.model.postprune, test, type = "class")

accuracy_postprun <- mean(test$pred == test$grad.year.5)

accuracy_postprun

```

<br>

We still end up with a highly complex tree that is difficult to interpret. Let's check to see what variables are considered important.

-   post-secondary pathway
-   range.school
-   Dem_Desc
-   CTE engagement
-   prep for post-secondary
-   Missing from this model
    -   Gender

<br>

```{r post pruning variable importance grad year +5 county, echo=TRUE}
meaningful.emp.ne.grad.year.5.model.postprune$variable.importance

importance <- meaningful.emp.ne.grad.year.5.model.postprune$variable.importance

importance <- sort(importance, decreasing = TRUE)

barplot(importance,
        main = "Variable Importance",
        xlab = "Variables",
        ylab = "Importance",
        col = "steelblue",
        las = 2,        # make axis labels vertical
        cex.names = 0.8) # smaller font if needed

```

<br>

Now let's compare the accuracy. The pre-pruned tree is the most accurate.

```{r compare accuracy grad year +0 county, echo=TRUE}
data.frame(base_accuracy, accuracy_preprun, accuracy_postprun)

```

<br>

### Summary

Overall, the variables that were the most consistently important throughout the analysis were;

-   Post-secondary pathways
    -   ps.grad.location
    -   ps.grad.InstitutionSector
    -   highest.cred.level
    -   ps.grad
-   CTE egnagement
-   High School characteristics
    -   Dem_Desc
    -   range.school
-   Post-secondary prep-work
    -   ACTCompositeScore
    -   MCA.M
    -   MCA.R
-   CTE engagement
    -   total.cte.courses.taken
    -   cte.achievement
-   Demographics
    -   Gender
    -   Economic status
    -   RaceEthnicty

<br>

## Ten years after graduation

Next we will look at the variables importance at five years after graduation. At this point we will bring back the post-secondary variables.

```{r prep meaningful emp ne grad year 10}
meaningful.emp.ne.grad.year.10 <- meaningful.emp.ne %>%
  filter(grad.year.10 != "After 2023") %>%
  filter(grad.year.10 != "Attending ps") %>%
  select(-PersonID, -grad.year.1, -grad.year.5)

kable(names(meaningful.emp.ne.grad.year.10))

```

<br>

### Base model

First we will split the data into two sets, Train and Test, in a 70:30 ratio. The Train set is used for training and creating the model. The Test set is considered to be a dummy production environment to test predictions and evaluate the accuracy of the model.

<br>

```{r split dataset into test and train meaningful emp ne grad year 10, echo=TRUE}
set.seed(1234)

sample_ind <- sample(nrow(meaningful.emp.ne.grad.year.10), nrow(meaningful.emp.ne.grad.year.10) *.7)

train <- meaningful.emp.ne.grad.year.10[sample_ind,]

test <- meaningful.emp.ne.grad.year.10[-sample_ind,]
```

Next, we create a decision tree model by calling the rpart function. Let's first create a base model with default parameters and value. The CP (complexity parameter) is used to control tree growth. If the cost of adding a variable is higher then the value of CP, then tree growth stops.

<br>

```{r create decision tree meaningful emp ne grad year 10, echo=TRUE, include = FALSE}
#Base model

meaningful.emp.ne.grad.year.10.model <- rpart(grad.year.10 ~ ., data = train, method = "class", cp = 0)

#Summary
summary(meaningful.emp.ne.grad.year.10.model)

```

```{r decision tree plot meaningful emp ne grad year 10}
#Plot tree
rpart.plot(meaningful.emp.ne.grad.year.10.model)

# Examine the complexity plot
printcp(meaningful.emp.ne.grad.year.10.model)

plotcp(meaningful.emp.ne.grad.year.10.model)

```

<br>

The resulting model produced a VERY complex tree with too many nodes that it isn't interpretable. However, examining the complexity parameters shows that I have an increasing cross-validated error which provides evidence of a decision tree with too much complexity.

Below are the values in variable important and it shows the following themes are important;

-   Post-secondary pathway
    -   ps.grad drops, though
-   CTE engagement
-   Post-secondary prep work
-   HS Characteristics - range.school & Dem_Desc
-   Demographics
    -   Gender
    -   RaceEthnicity
    -   SpecialEdStatus

<br>

```{r base model variable importance meaningful emp ne grad year 10, echo=TRUE}

meaningful.emp.ne.grad.year.10.model$variable.importance

```

Next, the accuracy of the model is computed and stored in a variable base_accuracy so we can compare it to our pruned trees later.

<br>

```{r model accuracy meaningful emp ne grad year 10, echo=TRUE}
test$pred <- predict(meaningful.emp.ne.grad.year.10.model, test, type = "class")

base_accuracy <- mean(test$pred == test$grad.year.10)

base_accuracy
```

### Pre-pruning

Next, we need to prune. We can either pre-prune or post-prune. We will start with pre-pruning and use each method - max depth, min depth, and min bucket.

<br>

```{r pre pruning  meaningful emp ne grad year 10, echo=TRUE}
# Grow a tree with minsplit of 40 and max depth of 10
meaningful.emp.ne.grad.year.10.model.preprune <- rpart(grad.year.10 ~ ., data = train, method = "class", 
                   control = rpart.control(cp = 0, maxdepth = 6, minsplit = 40))

```

```{r pre pruning summary meaningful emp ne grad year 10, include=FALSE}

#Summary
summary(meaningful.emp.ne.grad.year.10.model.preprune)
```

```{r pre pruning plot meaningful emp ne grad year 10, echo=TRUE}
#Plot tree
rpart.plot(meaningful.emp.ne.grad.year.10.model.preprune)

# Examine the complexity plot
printcp(meaningful.emp.ne.grad.year.10.model.preprune)
plotcp(meaningful.emp.ne.grad.year.10.model.preprune)


# Compute the accuracy of the pruned tree

test$pred <- predict(meaningful.emp.ne.grad.year.10.model.preprune, test, type = "class")

accuracy_preprun <- mean(test$pred == test$grad.year.10)

accuracy_preprun

```

<br>

The pre-pruning resulted in a significantly less complex tree with a .834 accuracy. Let's see what variables are important in this model.

The primary nodes are;

-   ps.grad.location
-   Dem_Desc
-   total.cte.courses.taken
-   range.school
-   MCA.M
-   pseo.participant

This model does indicate a difference in importance when pruned.

-   Post-secondary pathway
-   CTE engagement - the only one that leads to any sort of meaningful emp in NE
-   High school characteristics
-   Post-secondary prep
-   Demographics
-   Missing include
    -   ACTCompositeScore
    -   economic.status

<br>

```{r pre pruning variable importance meaningful emp ne grad year 10, echo=TRUE}
meaningful.emp.ne.grad.year.10.model.preprune$variable.importance
```

<br>

### Post-pruning

Next, let's try postpruning. The idea here is to allow the decision tree to grow fully and observe the CP value. Next, we prune/cut the tree with the optimal CP value as the parameter as shown in below code:

<br>

```{r postpruning meaningful emp ne grad year 10, echo=TRUE}
cp_table <- meaningful.emp.ne.grad.year.10.model$cptable

min_xerror <- min(cp_table[, "xerror"])
min_xerror_se <- cp_table[which.min(cp_table[,"xerror"]), "xstd"]

threshold <- min_xerror + min_xerror_se

one_se_index <- which(cp_table[, "xerror"] <= threshold)[1] 

cp_1se <- cp_table[one_se_index, "CP"]
# Prune the hr_base_model based on the optimal cp value
meaningful.emp.ne.grad.year.10.model.postprune <- prune(meaningful.emp.ne.grad.year.10.model, cp = 8.1911e-04)

#Summary
summary(meaningful.emp.ne.grad.year.10.model.postprune)

#Plot tree
rpart.plot(meaningful.emp.ne.grad.year.10.model.postprune)

# Examine the complexity plot
printcp(meaningful.emp.ne.grad.year.10.model.postprune)
plotcp(meaningful.emp.ne.grad.year.10.model.postprune)


# Compute the accuracy of the pruned tree

test$pred <- predict(meaningful.emp.ne.grad.year.10.model.postprune, test, type = "class")

accuracy_postprun <- mean(test$pred == test$grad.year.10)

accuracy_postprun

```

<br>

The accuracy is still a bit lower than pre-pruning - .8341776

We end up with a very simply tree. Let's check to see what variables are considered important.

-   Post-secondary pathway
-   Dem_Desc
-   CTE engagement

<br>

```{r post pruning variable importance meaningful emp ne grad year 10, echo=TRUE}
meaningful.emp.ne.grad.year.10.model.postprune$variable.importance

importance <- meaningful.emp.ne.grad.year.10.model.postprune$variable.importance

importance <- sort(importance, decreasing = TRUE)

barplot(importance,
        main = "Variable Importance",
        xlab = "Variables",
        ylab = "Importance",
        col = "steelblue",
        las = 2,        # make axis labels vertical
        cex.names = 0.8) # smaller font if needed

```

<br>

Now let's compare the accuracy. The prepruned tree/model looks to be the best.

```{r compare accuracy meaningful emp ne grad year 10, echo=TRUE}
data.frame(base_accuracy, accuracy_preprun, accuracy_postprun)

```

### Summary

Overall, the variables that were the most consistently important throughout the analysis were the following;

-   The post-secondary pathway
-   CTE engagement
-   High school characteristics - Dem_Desc & Range School
-   Post-secondary prep work
-   A few demographics
    -   Gender
    -   SpecialEdStatus
    -   RaceEthnicity

<br>

## Summary across time

-   1 year after graduation
    -   Post-secondary pathways
        -   ps.grad.location
        -   ps.grad.InstitutionSector
        -   highest.cred.level
        -   ps.grad
    -   HS Characteristics
        -   Dem_Desc
        -   range.school
    -   RaceEthnicity
    -   CTE engagement
    -   Gender
    -   College Prepwork
        -   MCA.M
-   5 years after graduation
    -   Post-secondary pathways
        -   ps.grad.location
        -   highest.cred.level
    -   HS characteristics
        -   Dem_Desc
        -   Range school
    -   College prepwork
        -   ACTCompositeScore
        -   pseo.participant
        -   MCA.M
        -   MCA.S
    -   CTE engagement
    -   Gender
-   10 years after graduation
    -   Post-secondary pathway
        -   ps.grad.location
    -   Dem_Desc
    -   CTE engagement
    -   Post-secondary prepwork

So what doesn't come up as much?

-   Demographic variables

    -   Gender
    -   grad.year.covid
    -   economic.status
    -   SpecialEdStatus
    -   english.learner

-   High school accomplishment

    -   pseo.participant

-   Post-secondary prep

    -   took.ACT

    -   MCA.S

    -   ap.exam

```{r master after analysis}
master.after.CART <- master %>%
  select(-Gender, -grad.year.covid, -economic.status, -SpecialEdStatus, -english.learner, -pseo.participant, -took.ACT, -MCA.S, -ap.exam)

write_csv(master.after.CART, "Data/SLEDS/Masters/After analysis/Master-after-CART.csv")

```
